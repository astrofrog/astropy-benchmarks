{
    "convolve.Convolve.time_convolve": {
        "code": "class Convolve:\n    def time_convolve(self, ndim, size, boundary, nan_treatment):\n        convolve(self.array, self.kernel,\n                 boundary=boundary, nan_treatment=nan_treatment)\n\n    def setup(self, ndim, size, boundary, nan_treatment):\n    \n        print(ndim, size, boundary, nan_treatment)\n    \n        np.random.seed(12345)\n    \n        self.kernel = np.random.random(kernel_shapes[ndim][size])\n        self.array = np.random.random(array_shapes[ndim][size])",
        "min_run_count": 2,
        "name": "convolve.Convolve.time_convolve",
        "number": 0,
        "param_names": [
            "ndim",
            "size",
            "boundary",
            "nan_treatment"
        ],
        "params": [
            [
                "1",
                "2",
                "3"
            ],
            [
                "'small'",
                "'large'"
            ],
            [
                "None",
                "'fill'",
                "'wrap'",
                "'extend'"
            ],
            [
                "'fill'",
                "'interpolate'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bf12ed205920e07473cfcf596eaeff59930bddb209c94f98948c2a4bb78c9e4f",
        "warmup_time": -1
    },
    "coordinates.FrameBenchmarks.time_concatenate_array": {
        "code": "class FrameBenchmarks:\n    def time_concatenate_array(self):\n        concatenate((self.icrs_array, self.icrs_array))\n\n    def setup(self):\n    \n        self.scalar_ra = 3.2 * u.deg\n        self.scalar_dec = 2.2 * u.deg\n    \n        self.scalar_pmra = 3.2 * u.mas/u.yr\n        self.scalar_pmdec = 2.2 * u.mas/u.yr\n    \n        self.array_ra = np.linspace(0., 360., 1000) * u.deg\n        self.array_dec = np.linspace(-90., 90., 1000) * u.deg\n    \n        np.random.seed(12345)\n        self.icrs_scalar = ICRS(ra=1*u.deg, dec=2*u.deg)\n        self.icrs_array = ICRS(ra=np.random.random(10000)*u.deg,\n                               dec=np.random.random(10000)*u.deg)\n    \n        # Some points to use for benchmarking coordinate matching.\n        # These were motivated by some tests done in astropy/astropy#7324:\n        # https://github.com/astropy/astropy/pull/7324#issuecomment-392382719\n        xyz_uniform1 = rnd.uniform(size=(3, 10000)) * u.kpc\n        xyz_uniform2 = rnd.uniform(size=(3, 10000)) * u.kpc\n        self.icrs_uniform1 = ICRS(xyz_uniform1,\n                                  representation_type=CartesianRepresentation)\n        self.icrs_uniform2 = ICRS(xyz_uniform2,\n                                  representation_type=CartesianRepresentation)\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph1 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph2 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n        self.icrs_uniform_sph1 = ICRS(\n            xyz_uniform_sph1, representation_type=CartesianRepresentation)\n        self.icrs_uniform_sph2 = ICRS(\n            xyz_uniform_sph2, representation_type=CartesianRepresentation)\n    \n        xyz0 = rnd.uniform(-100, 100, size=(8, 3))\n        xyz_clustered1 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        xyz_clustered2 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        self.icrs_clustered1 = ICRS(\n            xyz_clustered1, representation_type=CartesianRepresentation)\n        self.icrs_clustered2 = ICRS(\n            xyz_clustered2, representation_type=CartesianRepresentation)",
        "min_run_count": 2,
        "name": "coordinates.FrameBenchmarks.time_concatenate_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d9a8a1af0db07cab1ff7ab7f030eb466efc714e0b77a879085390d16d024300d",
        "warmup_time": -1
    },
    "coordinates.FrameBenchmarks.time_concatenate_scalar": {
        "code": "class FrameBenchmarks:\n    def time_concatenate_scalar(self):\n        concatenate((self.icrs_scalar, self.icrs_scalar))\n\n    def setup(self):\n    \n        self.scalar_ra = 3.2 * u.deg\n        self.scalar_dec = 2.2 * u.deg\n    \n        self.scalar_pmra = 3.2 * u.mas/u.yr\n        self.scalar_pmdec = 2.2 * u.mas/u.yr\n    \n        self.array_ra = np.linspace(0., 360., 1000) * u.deg\n        self.array_dec = np.linspace(-90., 90., 1000) * u.deg\n    \n        np.random.seed(12345)\n        self.icrs_scalar = ICRS(ra=1*u.deg, dec=2*u.deg)\n        self.icrs_array = ICRS(ra=np.random.random(10000)*u.deg,\n                               dec=np.random.random(10000)*u.deg)\n    \n        # Some points to use for benchmarking coordinate matching.\n        # These were motivated by some tests done in astropy/astropy#7324:\n        # https://github.com/astropy/astropy/pull/7324#issuecomment-392382719\n        xyz_uniform1 = rnd.uniform(size=(3, 10000)) * u.kpc\n        xyz_uniform2 = rnd.uniform(size=(3, 10000)) * u.kpc\n        self.icrs_uniform1 = ICRS(xyz_uniform1,\n                                  representation_type=CartesianRepresentation)\n        self.icrs_uniform2 = ICRS(xyz_uniform2,\n                                  representation_type=CartesianRepresentation)\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph1 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph2 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n        self.icrs_uniform_sph1 = ICRS(\n            xyz_uniform_sph1, representation_type=CartesianRepresentation)\n        self.icrs_uniform_sph2 = ICRS(\n            xyz_uniform_sph2, representation_type=CartesianRepresentation)\n    \n        xyz0 = rnd.uniform(-100, 100, size=(8, 3))\n        xyz_clustered1 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        xyz_clustered2 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        self.icrs_clustered1 = ICRS(\n            xyz_clustered1, representation_type=CartesianRepresentation)\n        self.icrs_clustered2 = ICRS(\n            xyz_clustered2, representation_type=CartesianRepresentation)",
        "min_run_count": 2,
        "name": "coordinates.FrameBenchmarks.time_concatenate_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "377a566e5922e38093d3816db9b6d23411e8bc0968bf8bb3615a19cecd7acca1",
        "warmup_time": -1
    },
    "coordinates.FrameBenchmarks.time_coord_match_clusters": {
        "code": "class FrameBenchmarks:\n    def time_coord_match_clusters(self):\n        match_coordinates_sky(self.icrs_clustered1, self.icrs_clustered2)\n\n    def setup(self):\n    \n        self.scalar_ra = 3.2 * u.deg\n        self.scalar_dec = 2.2 * u.deg\n    \n        self.scalar_pmra = 3.2 * u.mas/u.yr\n        self.scalar_pmdec = 2.2 * u.mas/u.yr\n    \n        self.array_ra = np.linspace(0., 360., 1000) * u.deg\n        self.array_dec = np.linspace(-90., 90., 1000) * u.deg\n    \n        np.random.seed(12345)\n        self.icrs_scalar = ICRS(ra=1*u.deg, dec=2*u.deg)\n        self.icrs_array = ICRS(ra=np.random.random(10000)*u.deg,\n                               dec=np.random.random(10000)*u.deg)\n    \n        # Some points to use for benchmarking coordinate matching.\n        # These were motivated by some tests done in astropy/astropy#7324:\n        # https://github.com/astropy/astropy/pull/7324#issuecomment-392382719\n        xyz_uniform1 = rnd.uniform(size=(3, 10000)) * u.kpc\n        xyz_uniform2 = rnd.uniform(size=(3, 10000)) * u.kpc\n        self.icrs_uniform1 = ICRS(xyz_uniform1,\n                                  representation_type=CartesianRepresentation)\n        self.icrs_uniform2 = ICRS(xyz_uniform2,\n                                  representation_type=CartesianRepresentation)\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph1 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph2 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n        self.icrs_uniform_sph1 = ICRS(\n            xyz_uniform_sph1, representation_type=CartesianRepresentation)\n        self.icrs_uniform_sph2 = ICRS(\n            xyz_uniform_sph2, representation_type=CartesianRepresentation)\n    \n        xyz0 = rnd.uniform(-100, 100, size=(8, 3))\n        xyz_clustered1 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        xyz_clustered2 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        self.icrs_clustered1 = ICRS(\n            xyz_clustered1, representation_type=CartesianRepresentation)\n        self.icrs_clustered2 = ICRS(\n            xyz_clustered2, representation_type=CartesianRepresentation)",
        "min_run_count": 2,
        "name": "coordinates.FrameBenchmarks.time_coord_match_clusters",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8c8d4504cba309fa1df25d7ebcc9011afbe10b7a8ae72bf2895372144fd5c296",
        "warmup_time": -1
    },
    "coordinates.FrameBenchmarks.time_coord_match_sphere": {
        "code": "class FrameBenchmarks:\n    def time_coord_match_sphere(self):\n        match_coordinates_sky(self.icrs_uniform_sph1, self.icrs_uniform_sph2)\n\n    def setup(self):\n    \n        self.scalar_ra = 3.2 * u.deg\n        self.scalar_dec = 2.2 * u.deg\n    \n        self.scalar_pmra = 3.2 * u.mas/u.yr\n        self.scalar_pmdec = 2.2 * u.mas/u.yr\n    \n        self.array_ra = np.linspace(0., 360., 1000) * u.deg\n        self.array_dec = np.linspace(-90., 90., 1000) * u.deg\n    \n        np.random.seed(12345)\n        self.icrs_scalar = ICRS(ra=1*u.deg, dec=2*u.deg)\n        self.icrs_array = ICRS(ra=np.random.random(10000)*u.deg,\n                               dec=np.random.random(10000)*u.deg)\n    \n        # Some points to use for benchmarking coordinate matching.\n        # These were motivated by some tests done in astropy/astropy#7324:\n        # https://github.com/astropy/astropy/pull/7324#issuecomment-392382719\n        xyz_uniform1 = rnd.uniform(size=(3, 10000)) * u.kpc\n        xyz_uniform2 = rnd.uniform(size=(3, 10000)) * u.kpc\n        self.icrs_uniform1 = ICRS(xyz_uniform1,\n                                  representation_type=CartesianRepresentation)\n        self.icrs_uniform2 = ICRS(xyz_uniform2,\n                                  representation_type=CartesianRepresentation)\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph1 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph2 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n        self.icrs_uniform_sph1 = ICRS(\n            xyz_uniform_sph1, representation_type=CartesianRepresentation)\n        self.icrs_uniform_sph2 = ICRS(\n            xyz_uniform_sph2, representation_type=CartesianRepresentation)\n    \n        xyz0 = rnd.uniform(-100, 100, size=(8, 3))\n        xyz_clustered1 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        xyz_clustered2 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        self.icrs_clustered1 = ICRS(\n            xyz_clustered1, representation_type=CartesianRepresentation)\n        self.icrs_clustered2 = ICRS(\n            xyz_clustered2, representation_type=CartesianRepresentation)",
        "min_run_count": 2,
        "name": "coordinates.FrameBenchmarks.time_coord_match_sphere",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3564f883f404bd6d53a21b9e3334ff6ce6af97655e2550fd6c6ef7825f59eb88",
        "warmup_time": -1
    },
    "coordinates.FrameBenchmarks.time_coord_match_uniform": {
        "code": "class FrameBenchmarks:\n    def time_coord_match_uniform(self):\n        match_coordinates_sky(self.icrs_uniform1, self.icrs_uniform2)\n\n    def setup(self):\n    \n        self.scalar_ra = 3.2 * u.deg\n        self.scalar_dec = 2.2 * u.deg\n    \n        self.scalar_pmra = 3.2 * u.mas/u.yr\n        self.scalar_pmdec = 2.2 * u.mas/u.yr\n    \n        self.array_ra = np.linspace(0., 360., 1000) * u.deg\n        self.array_dec = np.linspace(-90., 90., 1000) * u.deg\n    \n        np.random.seed(12345)\n        self.icrs_scalar = ICRS(ra=1*u.deg, dec=2*u.deg)\n        self.icrs_array = ICRS(ra=np.random.random(10000)*u.deg,\n                               dec=np.random.random(10000)*u.deg)\n    \n        # Some points to use for benchmarking coordinate matching.\n        # These were motivated by some tests done in astropy/astropy#7324:\n        # https://github.com/astropy/astropy/pull/7324#issuecomment-392382719\n        xyz_uniform1 = rnd.uniform(size=(3, 10000)) * u.kpc\n        xyz_uniform2 = rnd.uniform(size=(3, 10000)) * u.kpc\n        self.icrs_uniform1 = ICRS(xyz_uniform1,\n                                  representation_type=CartesianRepresentation)\n        self.icrs_uniform2 = ICRS(xyz_uniform2,\n                                  representation_type=CartesianRepresentation)\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph1 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph2 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n        self.icrs_uniform_sph1 = ICRS(\n            xyz_uniform_sph1, representation_type=CartesianRepresentation)\n        self.icrs_uniform_sph2 = ICRS(\n            xyz_uniform_sph2, representation_type=CartesianRepresentation)\n    \n        xyz0 = rnd.uniform(-100, 100, size=(8, 3))\n        xyz_clustered1 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        xyz_clustered2 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        self.icrs_clustered1 = ICRS(\n            xyz_clustered1, representation_type=CartesianRepresentation)\n        self.icrs_clustered2 = ICRS(\n            xyz_clustered2, representation_type=CartesianRepresentation)",
        "min_run_count": 2,
        "name": "coordinates.FrameBenchmarks.time_coord_match_uniform",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a094f6cec6d6468375e50b362b7bab22b093aba20c9a464a3d72adaae21d1c0a",
        "warmup_time": -1
    },
    "coordinates.FrameBenchmarks.time_init_array": {
        "code": "class FrameBenchmarks:\n    def time_init_array(self):\n        FK5(self.array_ra, self.array_dec)\n\n    def setup(self):\n    \n        self.scalar_ra = 3.2 * u.deg\n        self.scalar_dec = 2.2 * u.deg\n    \n        self.scalar_pmra = 3.2 * u.mas/u.yr\n        self.scalar_pmdec = 2.2 * u.mas/u.yr\n    \n        self.array_ra = np.linspace(0., 360., 1000) * u.deg\n        self.array_dec = np.linspace(-90., 90., 1000) * u.deg\n    \n        np.random.seed(12345)\n        self.icrs_scalar = ICRS(ra=1*u.deg, dec=2*u.deg)\n        self.icrs_array = ICRS(ra=np.random.random(10000)*u.deg,\n                               dec=np.random.random(10000)*u.deg)\n    \n        # Some points to use for benchmarking coordinate matching.\n        # These were motivated by some tests done in astropy/astropy#7324:\n        # https://github.com/astropy/astropy/pull/7324#issuecomment-392382719\n        xyz_uniform1 = rnd.uniform(size=(3, 10000)) * u.kpc\n        xyz_uniform2 = rnd.uniform(size=(3, 10000)) * u.kpc\n        self.icrs_uniform1 = ICRS(xyz_uniform1,\n                                  representation_type=CartesianRepresentation)\n        self.icrs_uniform2 = ICRS(xyz_uniform2,\n                                  representation_type=CartesianRepresentation)\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph1 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph2 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n        self.icrs_uniform_sph1 = ICRS(\n            xyz_uniform_sph1, representation_type=CartesianRepresentation)\n        self.icrs_uniform_sph2 = ICRS(\n            xyz_uniform_sph2, representation_type=CartesianRepresentation)\n    \n        xyz0 = rnd.uniform(-100, 100, size=(8, 3))\n        xyz_clustered1 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        xyz_clustered2 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        self.icrs_clustered1 = ICRS(\n            xyz_clustered1, representation_type=CartesianRepresentation)\n        self.icrs_clustered2 = ICRS(\n            xyz_clustered2, representation_type=CartesianRepresentation)",
        "min_run_count": 2,
        "name": "coordinates.FrameBenchmarks.time_init_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9dd0a9af08100d43cbb44afb12957e4a62200628da9d4f8e69396e3aedfe22ca",
        "warmup_time": -1
    },
    "coordinates.FrameBenchmarks.time_init_nodata": {
        "code": "class FrameBenchmarks:\n    def time_init_nodata(self):\n        FK5()\n\n    def setup(self):\n    \n        self.scalar_ra = 3.2 * u.deg\n        self.scalar_dec = 2.2 * u.deg\n    \n        self.scalar_pmra = 3.2 * u.mas/u.yr\n        self.scalar_pmdec = 2.2 * u.mas/u.yr\n    \n        self.array_ra = np.linspace(0., 360., 1000) * u.deg\n        self.array_dec = np.linspace(-90., 90., 1000) * u.deg\n    \n        np.random.seed(12345)\n        self.icrs_scalar = ICRS(ra=1*u.deg, dec=2*u.deg)\n        self.icrs_array = ICRS(ra=np.random.random(10000)*u.deg,\n                               dec=np.random.random(10000)*u.deg)\n    \n        # Some points to use for benchmarking coordinate matching.\n        # These were motivated by some tests done in astropy/astropy#7324:\n        # https://github.com/astropy/astropy/pull/7324#issuecomment-392382719\n        xyz_uniform1 = rnd.uniform(size=(3, 10000)) * u.kpc\n        xyz_uniform2 = rnd.uniform(size=(3, 10000)) * u.kpc\n        self.icrs_uniform1 = ICRS(xyz_uniform1,\n                                  representation_type=CartesianRepresentation)\n        self.icrs_uniform2 = ICRS(xyz_uniform2,\n                                  representation_type=CartesianRepresentation)\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph1 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph2 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n        self.icrs_uniform_sph1 = ICRS(\n            xyz_uniform_sph1, representation_type=CartesianRepresentation)\n        self.icrs_uniform_sph2 = ICRS(\n            xyz_uniform_sph2, representation_type=CartesianRepresentation)\n    \n        xyz0 = rnd.uniform(-100, 100, size=(8, 3))\n        xyz_clustered1 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        xyz_clustered2 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        self.icrs_clustered1 = ICRS(\n            xyz_clustered1, representation_type=CartesianRepresentation)\n        self.icrs_clustered2 = ICRS(\n            xyz_clustered2, representation_type=CartesianRepresentation)",
        "min_run_count": 2,
        "name": "coordinates.FrameBenchmarks.time_init_nodata",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3de6a4d1c00c390fc1c099914a2ba625d79fc4c85f45592bf67bb8e535b38e42",
        "warmup_time": -1
    },
    "coordinates.FrameBenchmarks.time_init_scalar": {
        "code": "class FrameBenchmarks:\n    def time_init_scalar(self):\n        FK5(self.scalar_ra, self.scalar_dec)\n\n    def setup(self):\n    \n        self.scalar_ra = 3.2 * u.deg\n        self.scalar_dec = 2.2 * u.deg\n    \n        self.scalar_pmra = 3.2 * u.mas/u.yr\n        self.scalar_pmdec = 2.2 * u.mas/u.yr\n    \n        self.array_ra = np.linspace(0., 360., 1000) * u.deg\n        self.array_dec = np.linspace(-90., 90., 1000) * u.deg\n    \n        np.random.seed(12345)\n        self.icrs_scalar = ICRS(ra=1*u.deg, dec=2*u.deg)\n        self.icrs_array = ICRS(ra=np.random.random(10000)*u.deg,\n                               dec=np.random.random(10000)*u.deg)\n    \n        # Some points to use for benchmarking coordinate matching.\n        # These were motivated by some tests done in astropy/astropy#7324:\n        # https://github.com/astropy/astropy/pull/7324#issuecomment-392382719\n        xyz_uniform1 = rnd.uniform(size=(3, 10000)) * u.kpc\n        xyz_uniform2 = rnd.uniform(size=(3, 10000)) * u.kpc\n        self.icrs_uniform1 = ICRS(xyz_uniform1,\n                                  representation_type=CartesianRepresentation)\n        self.icrs_uniform2 = ICRS(xyz_uniform2,\n                                  representation_type=CartesianRepresentation)\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph1 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph2 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n        self.icrs_uniform_sph1 = ICRS(\n            xyz_uniform_sph1, representation_type=CartesianRepresentation)\n        self.icrs_uniform_sph2 = ICRS(\n            xyz_uniform_sph2, representation_type=CartesianRepresentation)\n    \n        xyz0 = rnd.uniform(-100, 100, size=(8, 3))\n        xyz_clustered1 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        xyz_clustered2 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        self.icrs_clustered1 = ICRS(\n            xyz_clustered1, representation_type=CartesianRepresentation)\n        self.icrs_clustered2 = ICRS(\n            xyz_clustered2, representation_type=CartesianRepresentation)",
        "min_run_count": 2,
        "name": "coordinates.FrameBenchmarks.time_init_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "64b79a07d8ce0eea2f8be87c1422b9915b414f7e640810bd427f81733a684c99",
        "warmup_time": -1
    },
    "coordinates.FrameBenchmarks.time_init_scalar_diff": {
        "code": "class FrameBenchmarks:\n    def time_init_scalar_diff(self):\n        FK5(self.scalar_ra, self.scalar_dec,\n            pm_ra_cosdec=self.scalar_pmra,\n            pm_dec=self.scalar_pmdec)\n\n    def setup(self):\n    \n        self.scalar_ra = 3.2 * u.deg\n        self.scalar_dec = 2.2 * u.deg\n    \n        self.scalar_pmra = 3.2 * u.mas/u.yr\n        self.scalar_pmdec = 2.2 * u.mas/u.yr\n    \n        self.array_ra = np.linspace(0., 360., 1000) * u.deg\n        self.array_dec = np.linspace(-90., 90., 1000) * u.deg\n    \n        np.random.seed(12345)\n        self.icrs_scalar = ICRS(ra=1*u.deg, dec=2*u.deg)\n        self.icrs_array = ICRS(ra=np.random.random(10000)*u.deg,\n                               dec=np.random.random(10000)*u.deg)\n    \n        # Some points to use for benchmarking coordinate matching.\n        # These were motivated by some tests done in astropy/astropy#7324:\n        # https://github.com/astropy/astropy/pull/7324#issuecomment-392382719\n        xyz_uniform1 = rnd.uniform(size=(3, 10000)) * u.kpc\n        xyz_uniform2 = rnd.uniform(size=(3, 10000)) * u.kpc\n        self.icrs_uniform1 = ICRS(xyz_uniform1,\n                                  representation_type=CartesianRepresentation)\n        self.icrs_uniform2 = ICRS(xyz_uniform2,\n                                  representation_type=CartesianRepresentation)\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph1 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n    \n        phi = rnd.uniform(0, 2*np.pi, size=10000)\n        theta = np.arccos(2*rnd.uniform(size=10000) - 1)\n        xyz_uniform_sph2 = np.vstack((np.cos(phi)*np.sin(theta),\n                                      np.sin(phi)*np.sin(theta),\n                                      np.cos(theta))) * u.kpc\n        self.icrs_uniform_sph1 = ICRS(\n            xyz_uniform_sph1, representation_type=CartesianRepresentation)\n        self.icrs_uniform_sph2 = ICRS(\n            xyz_uniform_sph2, representation_type=CartesianRepresentation)\n    \n        xyz0 = rnd.uniform(-100, 100, size=(8, 3))\n        xyz_clustered1 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        xyz_clustered2 = np.vstack(rnd.normal(xyz0, size=(10000, 8, 3))).T * u.kpc\n        self.icrs_clustered1 = ICRS(\n            xyz_clustered1, representation_type=CartesianRepresentation)\n        self.icrs_clustered2 = ICRS(\n            xyz_clustered2, representation_type=CartesianRepresentation)",
        "min_run_count": 2,
        "name": "coordinates.FrameBenchmarks.time_init_scalar_diff",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7661b4eb62bd7efea9dc2bb5bc4af216cd23919eca3a415675d2cebe4f0b4e4d",
        "warmup_time": -1
    },
    "coordinates.RepresentationBenchmarks.time_with_differentials_array": {
        "code": "class RepresentationBenchmarks:\n    def time_with_differentials_array(self):\n        self.array_rep.with_differentials(self.array_dif)\n\n    def setup(self):\n    \n        # Avoid top-level module import to make sure that the benchmarks are\n        # compatible with versions of astropy that did not have this functionality.\n        from astropy.coordinates import CartesianDifferential\n    \n        self.scalar_rep = CartesianRepresentation([1., 2, 3] * u.kpc)\n        self.scalar_dif = CartesianDifferential([1, 2, 3.] * u.km/u.s)\n    \n        self.array_rep = CartesianRepresentation(np.ones((3, 1000)) * u.kpc)\n        self.array_dif = CartesianDifferential(np.ones((3, 1000)) * u.km/u.s)",
        "min_run_count": 2,
        "name": "coordinates.RepresentationBenchmarks.time_with_differentials_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ea5b8a8d6522a15a7037a7e20517f65435da8b1962d1fc28da1fcca6400226d8",
        "warmup_time": -1
    },
    "coordinates.RepresentationBenchmarks.time_with_differentials_scalar": {
        "code": "class RepresentationBenchmarks:\n    def time_with_differentials_scalar(self):\n        self.scalar_rep.with_differentials(self.scalar_dif)\n\n    def setup(self):\n    \n        # Avoid top-level module import to make sure that the benchmarks are\n        # compatible with versions of astropy that did not have this functionality.\n        from astropy.coordinates import CartesianDifferential\n    \n        self.scalar_rep = CartesianRepresentation([1., 2, 3] * u.kpc)\n        self.scalar_dif = CartesianDifferential([1, 2, 3.] * u.km/u.s)\n    \n        self.array_rep = CartesianRepresentation(np.ones((3, 1000)) * u.kpc)\n        self.array_dif = CartesianDifferential(np.ones((3, 1000)) * u.km/u.s)",
        "min_run_count": 2,
        "name": "coordinates.RepresentationBenchmarks.time_with_differentials_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e5b3b94e549e3d9ebf56b77e0023426d9f175091679bddb5f381414aeed2fd4b",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_icrs_to_galactic_array": {
        "code": "class SkyCoordBenchmarks:\n    def time_icrs_to_galactic_array(self):\n        self.coord_array_1e6.transform_to('galactic')\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_icrs_to_galactic_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6918c6ca278f7e282233d1a613a666e12d3db465f97f3f943077ff24883c0102",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_icrs_to_galactic_scalar": {
        "code": "class SkyCoordBenchmarks:\n    def time_icrs_to_galactic_scalar(self):\n        self.coord_scalar.transform_to('galactic')\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_icrs_to_galactic_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4371461be3fbec6d1e2eb85c480e89ebb05c1a4d3b23f3e9442445264c770f95",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_init_array": {
        "code": "class SkyCoordBenchmarks:\n    def time_init_array(self):\n        SkyCoord(self.lon_1e6, self.lat_1e6, unit='deg', frame='icrs')\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_init_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "273c7b66248421d01e454afe76c992ac13ee8da5d53b31230bf44817582b4957",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_init_quantity_array_keyword": {
        "code": "class SkyCoordBenchmarks:\n    def time_init_quantity_array_keyword(self):\n        SkyCoord(ra=self.array_q_ra, dec=self.array_q_dec)\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_init_quantity_array_keyword",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "228c3b5290e1a7523e150ace3755c584231f7fc3f5de85a3e148e3ad6d079d56",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_init_quantity_array_positional": {
        "code": "class SkyCoordBenchmarks:\n    def time_init_quantity_array_positional(self):\n        SkyCoord(self.array_q_ra, self.array_q_dec)\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_init_quantity_array_positional",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "84d91d570508630e25dcc267565c57ce6f9190479df1c663121c736a0d6c15f1",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_init_quantity_scalar_keyword": {
        "code": "class SkyCoordBenchmarks:\n    def time_init_quantity_scalar_keyword(self):\n        SkyCoord(ra=self.scalar_q_ra, dec=self.scalar_q_dec)\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_init_quantity_scalar_keyword",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6348fe2890a5b4473195b1f7563c87ad57f2bdefb89ea98f5100a6ada7d06e9e",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_init_quantity_scalar_positional": {
        "code": "class SkyCoordBenchmarks:\n    def time_init_quantity_scalar_positional(self):\n        SkyCoord(self.scalar_q_ra, self.scalar_q_dec)\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_init_quantity_scalar_positional",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3ca05a73377c056edac1cd48846b6936f47895cef3b380972da0c85ae3d5f587",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_init_quantity_scalar_positional_fk5_frame": {
        "code": "class SkyCoordBenchmarks:\n    def time_init_quantity_scalar_positional_fk5_frame(self):\n        SkyCoord(self.scalar_q_ra, self.scalar_q_dec,\n                 frame=fk5_J2010)\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_init_quantity_scalar_positional_fk5_frame",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a4efb71d10727b763b5a7c811925b0d9465dfcf14ff3982051fc00083d67d6d2",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_init_quantity_scalar_positional_fk5_frame_extra_kwargs": {
        "code": "class SkyCoordBenchmarks:\n    def time_init_quantity_scalar_positional_fk5_frame_extra_kwargs(self):\n        SkyCoord(self.scalar_q_ra, self.scalar_q_dec,\n                 frame=fk5_J2010, obstime=J2010)\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_init_quantity_scalar_positional_fk5_frame_extra_kwargs",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "154c9dc8471faafe661a677aac2b53617f884f3bd5c477a703c4946bb6c71eea",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_init_quantity_scalar_positional_fk5_kwarg": {
        "code": "class SkyCoordBenchmarks:\n    def time_init_quantity_scalar_positional_fk5_kwarg(self):\n        SkyCoord(self.scalar_q_ra, self.scalar_q_dec,\n                 frame='fk5', equinox=J2010)\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_init_quantity_scalar_positional_fk5_kwarg",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ae5bff79320c7ca0bc37bc9acb491b50e2e15e79608cc4115d485458bcdfdce5",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_init_repr_array_noframe": {
        "code": "class SkyCoordBenchmarks:\n    def time_init_repr_array_noframe(self):\n        SkyCoord(self.array_repr)\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_init_repr_array_noframe",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eefda7caa996d6ea6f20de39e85eca14ee2923e68b15e61739d8aed4ac276d67",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_init_repr_scalar_noframe": {
        "code": "class SkyCoordBenchmarks:\n    def time_init_repr_scalar_noframe(self):\n        SkyCoord(self.scalar_repr)\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_init_repr_scalar_noframe",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7ebda1373d9d66ea63bbd9978e45706c205eb72d3caa32b8cec944aa56833127",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_init_scalar": {
        "code": "class SkyCoordBenchmarks:\n    def time_init_scalar(self):\n        SkyCoord(1, 2, unit='deg', frame='icrs')\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_init_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0685d7303c02a13f2e42eb6f13a8752c049f4638b7c54b60aefda722119a1664",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_iter_array": {
        "code": "class SkyCoordBenchmarks:\n    def time_iter_array(self):\n        for c in self.coord_array_1e3:\n            pass\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_iter_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1adc399feb7e9134018548bf35fb5f2d6715353410a37ab1aeb0f1db8709a905",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_repr_array": {
        "code": "class SkyCoordBenchmarks:\n    def time_repr_array(self):\n        repr(self.coord_array_1e3)\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_repr_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6a31bf4c63967f9cc612e423d27ee13dcade1c4cdcd51c8c8c74715bebd5eab8",
        "warmup_time": -1
    },
    "coordinates.SkyCoordBenchmarks.time_repr_scalar": {
        "code": "class SkyCoordBenchmarks:\n    def time_repr_scalar(self):\n        repr(self.coord_scalar)\n\n    def setup(self):\n    \n        self.coord_scalar = SkyCoord(1, 2, unit='deg', frame='icrs')\n    \n        lon, lat = np.ones((2, 1000))\n        self.coord_array_1e3 = SkyCoord(lon, lat, unit='deg', frame='icrs')\n    \n        self.lon_1e6, self.lat_1e6 = np.ones((2, int(1e6)))\n        self.coord_array_1e6 = SkyCoord(self.lon_1e6, self.lat_1e6,\n                                        unit='deg', frame='icrs')\n    \n        self.scalar_q_ra = 1 * u.deg\n        self.scalar_q_dec = 2 * u.deg\n    \n        np.random.seed(12345)\n        self.array_q_ra = np.random.rand(int(1e6)) * 360 * u.deg\n        self.array_q_dec = (np.random.rand(int(1e6)) * 180 - 90) * u.deg\n    \n        self.scalar_repr = UnitSphericalRepresentation(lat=self.scalar_q_dec,\n                                                       lon=self.scalar_q_ra)\n        self.array_repr = UnitSphericalRepresentation(lat=self.array_q_dec,\n                                                      lon=self.array_q_ra)",
        "min_run_count": 2,
        "name": "coordinates.SkyCoordBenchmarks.time_repr_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9049bec253bea2f918e9cca490d39804c1d067babefbfc0c16b508455abff8e4",
        "warmup_time": -1
    },
    "coordinates.time_angle_array_repr": {
        "code": "def time_angle_array_repr():\n    # Prior to Astropy 3.0, this was very inefficient\n    repr(ANGLES)",
        "min_run_count": 2,
        "name": "coordinates.time_angle_array_repr",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f7358d7eaaa2c43a08c409093a9da4c8824ee2c56f680a47906562bb1ce67d7c",
        "warmup_time": -1
    },
    "coordinates.time_angle_array_repr_latex": {
        "code": "def time_angle_array_repr_latex():\n    # Prior to Astropy 3.0, this was very inefficient\n    ANGLES._repr_latex_()",
        "min_run_count": 2,
        "name": "coordinates.time_angle_array_repr_latex",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d791293d91b6bf48d25ec937a4650655e13e232dd2136182811357cc4641fdef",
        "warmup_time": -1
    },
    "coordinates.time_angle_array_str": {
        "code": "def time_angle_array_str():\n    # Prior to Astropy 3.0, this was very inefficient\n    str(ANGLES)",
        "min_run_count": 2,
        "name": "coordinates.time_angle_array_str",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bb01074796e6a03b8b0c30b44045048769af753ecbe7b2ec8bf460be6bb73160",
        "warmup_time": -1
    },
    "coordinates.time_latitude": {
        "code": "def time_latitude():\n    Latitude(3.2, u.degree)",
        "min_run_count": 2,
        "name": "coordinates.time_latitude",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d37e722e0c0f585281e1f368dc32f3943dd8cf1ec4009924181467dd2c3a6cd0",
        "warmup_time": -1
    },
    "cosmology.LambdaCDMBenchmarks.time_age": {
        "code": "class LambdaCDMBenchmarks:\n    def time_age(self, cosmo):\n        self.cosmology.age(self.test_zs)\n\n    def setup(self, cosmo):\n        self.cosmology = cosmo\n        self.test_zs = np.linspace(0.1, 5.0, 200)",
        "min_run_count": 2,
        "name": "cosmology.LambdaCDMBenchmarks.time_age",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "LambdaCDM(H0=65 km / (Mpc s), Om0=0.6, Ode0=0.7, Tcmb0=0 K, Neff=3.04, m_nu=None, Ob0=None)",
                "LambdaCDM(H0=65 km / (Mpc s), Om0=0.25, Ode0=0.65, Tcmb0=2.7 K, Neff=3.04, m_nu=[0. 0. 0.] eV, Ob0=None)",
                "LambdaCDM(H0=65 km / (Mpc s), Om0=0.6, Ode0=0.7, Tcmb0=2.7 K, Neff=4, m_nu=[0. 0. 0. 0.] eV, Ob0=None)",
                "LambdaCDM(H0=65 km / (Mpc s), Om0=0.4, Ode0=0.2, Tcmb0=2.7 K, Neff=3.04, m_nu=[0. 0. 0.] eV, Ob0=None)",
                "FlatLambdaCDM(H0=65 km / (Mpc s), Om0=0.25, Tcmb0=0 K, Neff=3.04, m_nu=None, Ob0=None)",
                "FlatLambdaCDM(H0=65 km / (Mpc s), Om0=0.25, Tcmb0=2.7 K, Neff=3.04, m_nu=[0. 0. 0.] eV, Ob0=None)",
                "FlatLambdaCDM(H0=65 km / (Mpc s), Om0=0.25, Tcmb0=2.7 K, Neff=3.04, m_nu=[0.05 0.1  0.15] eV, Ob0=None)"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9d18698d04bfa5d55ddcae0f12ee69266bfed44f4b0fd81018487132da078301",
        "warmup_time": -1
    },
    "cosmology.LambdaCDMBenchmarks.time_lumdist": {
        "code": "class LambdaCDMBenchmarks:\n    def time_lumdist(self, cosmo):\n        self.cosmology.luminosity_distance(self.test_zs)\n\n    def setup(self, cosmo):\n        self.cosmology = cosmo\n        self.test_zs = np.linspace(0.1, 5.0, 200)",
        "min_run_count": 2,
        "name": "cosmology.LambdaCDMBenchmarks.time_lumdist",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "LambdaCDM(H0=65 km / (Mpc s), Om0=0.6, Ode0=0.7, Tcmb0=0 K, Neff=3.04, m_nu=None, Ob0=None)",
                "LambdaCDM(H0=65 km / (Mpc s), Om0=0.25, Ode0=0.65, Tcmb0=2.7 K, Neff=3.04, m_nu=[0. 0. 0.] eV, Ob0=None)",
                "LambdaCDM(H0=65 km / (Mpc s), Om0=0.6, Ode0=0.7, Tcmb0=2.7 K, Neff=4, m_nu=[0. 0. 0. 0.] eV, Ob0=None)",
                "LambdaCDM(H0=65 km / (Mpc s), Om0=0.4, Ode0=0.2, Tcmb0=2.7 K, Neff=3.04, m_nu=[0. 0. 0.] eV, Ob0=None)",
                "FlatLambdaCDM(H0=65 km / (Mpc s), Om0=0.25, Tcmb0=0 K, Neff=3.04, m_nu=None, Ob0=None)",
                "FlatLambdaCDM(H0=65 km / (Mpc s), Om0=0.25, Tcmb0=2.7 K, Neff=3.04, m_nu=[0. 0. 0.] eV, Ob0=None)",
                "FlatLambdaCDM(H0=65 km / (Mpc s), Om0=0.25, Tcmb0=2.7 K, Neff=3.04, m_nu=[0.05 0.1  0.15] eV, Ob0=None)"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5bac457205366118e159292716591c45c0cfc49c2e2729149b83abfbb3e6ed3e",
        "warmup_time": -1
    },
    "io_ascii.core.CoreSuite.time_base_splitter": {
        "code": "class CoreSuite:\n    def time_base_splitter(self):\n        core.BaseSplitter().process_val(self.line)\n\n    def setup(self):\n        self.lines = []\n        options = [['a b c d'], ['a b c \\\\', 'd'], ['a b \\\\', 'c \\\\', 'd'],\n                   ['a b \\\\', 'c d'], ['a \\\\', 'b c \\\\', 'd']]\n        for i in range(1000):\n            self.lines.extend(options[i % 5])\n        options = ['\"a\\tbc\\t\\td\"', 'ab cd', '\\tab\\t\\tc\\td', 'a \\tb \\tcd']\n        self.line = ''.join([options[i % 4] for i in range(1000)])\n        self.vals = [randword() for i in range(1000)]\n        self.csv_line = ','.join([str(x) for x in self.vals])\n        lst = []\n        lst.append([random.randint(-500, 500) for i in range(1000)])\n        lst.append([random.random() * 500 - 500 for i in range(1000)])\n        lst.append([''.join([random.choice(uppercase) for j in\n                            range(6)]) for i in range(1000)])\n        self.cols = [core.Column(str(i + 1)) for i in range(3)]\n        for col, x in izip(self.cols, lst):\n            col.str_vals = [str(s) for s in x]",
        "min_run_count": 2,
        "name": "io_ascii.core.CoreSuite.time_base_splitter",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ef95250cdacbcad30d437c583c0005f2e0f100ed28e242aea22dfd55507626f2",
        "warmup_time": -1
    },
    "io_ascii.core.CoreSuite.time_continuation_inputter": {
        "code": "class CoreSuite:\n    def time_continuation_inputter(self):\n        core.ContinuationLinesInputter().process_lines(self.lines)\n\n    def setup(self):\n        self.lines = []\n        options = [['a b c d'], ['a b c \\\\', 'd'], ['a b \\\\', 'c \\\\', 'd'],\n                   ['a b \\\\', 'c d'], ['a \\\\', 'b c \\\\', 'd']]\n        for i in range(1000):\n            self.lines.extend(options[i % 5])\n        options = ['\"a\\tbc\\t\\td\"', 'ab cd', '\\tab\\t\\tc\\td', 'a \\tb \\tcd']\n        self.line = ''.join([options[i % 4] for i in range(1000)])\n        self.vals = [randword() for i in range(1000)]\n        self.csv_line = ','.join([str(x) for x in self.vals])\n        lst = []\n        lst.append([random.randint(-500, 500) for i in range(1000)])\n        lst.append([random.random() * 500 - 500 for i in range(1000)])\n        lst.append([''.join([random.choice(uppercase) for j in\n                            range(6)]) for i in range(1000)])\n        self.cols = [core.Column(str(i + 1)) for i in range(3)]\n        for col, x in izip(self.cols, lst):\n            col.str_vals = [str(s) for s in x]",
        "min_run_count": 2,
        "name": "io_ascii.core.CoreSuite.time_continuation_inputter",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "406566039a7c4a88ddbba6da758e5757bc52acdbf7fe159d5324696a33b7f960",
        "warmup_time": -1
    },
    "io_ascii.core.CoreSuite.time_convert_vals": {
        "code": "class CoreSuite:\n    def time_convert_vals(self):\n        core.TableOutputter()._convert_vals(self.cols)\n\n    def setup(self):\n        self.lines = []\n        options = [['a b c d'], ['a b c \\\\', 'd'], ['a b \\\\', 'c \\\\', 'd'],\n                   ['a b \\\\', 'c d'], ['a \\\\', 'b c \\\\', 'd']]\n        for i in range(1000):\n            self.lines.extend(options[i % 5])\n        options = ['\"a\\tbc\\t\\td\"', 'ab cd', '\\tab\\t\\tc\\td', 'a \\tb \\tcd']\n        self.line = ''.join([options[i % 4] for i in range(1000)])\n        self.vals = [randword() for i in range(1000)]\n        self.csv_line = ','.join([str(x) for x in self.vals])\n        lst = []\n        lst.append([random.randint(-500, 500) for i in range(1000)])\n        lst.append([random.random() * 500 - 500 for i in range(1000)])\n        lst.append([''.join([random.choice(uppercase) for j in\n                            range(6)]) for i in range(1000)])\n        self.cols = [core.Column(str(i + 1)) for i in range(3)]\n        for col, x in izip(self.cols, lst):\n            col.str_vals = [str(s) for s in x]",
        "min_run_count": 2,
        "name": "io_ascii.core.CoreSuite.time_convert_vals",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0c660365b4b3180a53e83e7b346bbb72270cbb17c23a7b9c343b9e62bd6be16d",
        "warmup_time": -1
    },
    "io_ascii.core.CoreSuite.time_default_splitter_call": {
        "code": "class CoreSuite:\n    def time_default_splitter_call(self):\n        core.DefaultSplitter()(self.csv_line)\n\n    def setup(self):\n        self.lines = []\n        options = [['a b c d'], ['a b c \\\\', 'd'], ['a b \\\\', 'c \\\\', 'd'],\n                   ['a b \\\\', 'c d'], ['a \\\\', 'b c \\\\', 'd']]\n        for i in range(1000):\n            self.lines.extend(options[i % 5])\n        options = ['\"a\\tbc\\t\\td\"', 'ab cd', '\\tab\\t\\tc\\td', 'a \\tb \\tcd']\n        self.line = ''.join([options[i % 4] for i in range(1000)])\n        self.vals = [randword() for i in range(1000)]\n        self.csv_line = ','.join([str(x) for x in self.vals])\n        lst = []\n        lst.append([random.randint(-500, 500) for i in range(1000)])\n        lst.append([random.random() * 500 - 500 for i in range(1000)])\n        lst.append([''.join([random.choice(uppercase) for j in\n                            range(6)]) for i in range(1000)])\n        self.cols = [core.Column(str(i + 1)) for i in range(3)]\n        for col, x in izip(self.cols, lst):\n            col.str_vals = [str(s) for s in x]",
        "min_run_count": 2,
        "name": "io_ascii.core.CoreSuite.time_default_splitter_call",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9b11dacb692c8e31688afc0031aa584030b2b4311f16ab0de8e61d1111f68568",
        "warmup_time": -1
    },
    "io_ascii.core.CoreSuite.time_default_splitter_join": {
        "code": "class CoreSuite:\n    def time_default_splitter_join(self):\n        core.DefaultSplitter().join(self.vals)\n\n    def setup(self):\n        self.lines = []\n        options = [['a b c d'], ['a b c \\\\', 'd'], ['a b \\\\', 'c \\\\', 'd'],\n                   ['a b \\\\', 'c d'], ['a \\\\', 'b c \\\\', 'd']]\n        for i in range(1000):\n            self.lines.extend(options[i % 5])\n        options = ['\"a\\tbc\\t\\td\"', 'ab cd', '\\tab\\t\\tc\\td', 'a \\tb \\tcd']\n        self.line = ''.join([options[i % 4] for i in range(1000)])\n        self.vals = [randword() for i in range(1000)]\n        self.csv_line = ','.join([str(x) for x in self.vals])\n        lst = []\n        lst.append([random.randint(-500, 500) for i in range(1000)])\n        lst.append([random.random() * 500 - 500 for i in range(1000)])\n        lst.append([''.join([random.choice(uppercase) for j in\n                            range(6)]) for i in range(1000)])\n        self.cols = [core.Column(str(i + 1)) for i in range(3)]\n        for col, x in izip(self.cols, lst):\n            col.str_vals = [str(s) for s in x]",
        "min_run_count": 2,
        "name": "io_ascii.core.CoreSuite.time_default_splitter_join",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "306bb839233283dd45a91d2646131b786fecc79198f55c91a843d8d05bbf062a",
        "warmup_time": -1
    },
    "io_ascii.core.CoreSuite.time_whitespace_splitter": {
        "code": "class CoreSuite:\n    def time_whitespace_splitter(self):\n        core.WhitespaceSplitter().process_line(self.line)\n\n    def setup(self):\n        self.lines = []\n        options = [['a b c d'], ['a b c \\\\', 'd'], ['a b \\\\', 'c \\\\', 'd'],\n                   ['a b \\\\', 'c d'], ['a \\\\', 'b c \\\\', 'd']]\n        for i in range(1000):\n            self.lines.extend(options[i % 5])\n        options = ['\"a\\tbc\\t\\td\"', 'ab cd', '\\tab\\t\\tc\\td', 'a \\tb \\tcd']\n        self.line = ''.join([options[i % 4] for i in range(1000)])\n        self.vals = [randword() for i in range(1000)]\n        self.csv_line = ','.join([str(x) for x in self.vals])\n        lst = []\n        lst.append([random.randint(-500, 500) for i in range(1000)])\n        lst.append([random.random() * 500 - 500 for i in range(1000)])\n        lst.append([''.join([random.choice(uppercase) for j in\n                            range(6)]) for i in range(1000)])\n        self.cols = [core.Column(str(i + 1)) for i in range(3)]\n        for col, x in izip(self.cols, lst):\n            col.str_vals = [str(s) for s in x]",
        "min_run_count": 2,
        "name": "io_ascii.core.CoreSuite.time_whitespace_splitter",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ab9241b763369886db83aff56a4a41a13296bdc6de02fd6cca426503e4195b81",
        "warmup_time": -1
    },
    "io_ascii.fixedwidth.FixedWidthSuite.time_header": {
        "code": "class FixedWidthSuite:\n    def time_header(self):\n        self.header.get_cols(self.lines)\n\n    def setup(self):\n        self.header = ascii.FixedWidthHeader()\n        self.header.start_line = 0\n        self.header.col_starts = None\n        self.header.col_ends = None\n        self.splitter = ascii.FixedWidthSplitter()\n        f = open(os.path.join(HERE, 'files', 'fixed_width', 'string.txt'))\n        self.lines = f.read().split('\\n')\n        f.close()\n        self.header.get_cols(self.lines)\n        self.splitter.cols = self.header.cols\n        self.data = ascii.FixedWidthData()",
        "min_run_count": 2,
        "name": "io_ascii.fixedwidth.FixedWidthSuite.time_header",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ab31959770db8530c2a7211c49c8d5a7db6c42b75ff8fb0bac4be7689f1837ea",
        "warmup_time": -1
    },
    "io_ascii.fixedwidth.FixedWidthSuite.time_splitter": {
        "code": "class FixedWidthSuite:\n    def time_splitter(self):\n        self.splitter(self.lines[1:])\n\n    def setup(self):\n        self.header = ascii.FixedWidthHeader()\n        self.header.start_line = 0\n        self.header.col_starts = None\n        self.header.col_ends = None\n        self.splitter = ascii.FixedWidthSplitter()\n        f = open(os.path.join(HERE, 'files', 'fixed_width', 'string.txt'))\n        self.lines = f.read().split('\\n')\n        f.close()\n        self.header.get_cols(self.lines)\n        self.splitter.cols = self.header.cols\n        self.data = ascii.FixedWidthData()",
        "min_run_count": 2,
        "name": "io_ascii.fixedwidth.FixedWidthSuite.time_splitter",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a8f2eed392691b8fede23e560b4b933aef960db35ac1dafac4857c53e839ecf0",
        "warmup_time": -1
    },
    "io_ascii.ipac.IPACSuite.time_data_str_vals": {
        "code": "class IPACSuite:\n    def time_data_str_vals(self):\n        self.data.str_vals()\n\n    def setup(self):\n    \n        self.vals = [str(i + 1) for i in range(1000)]\n        self.widths = [i + 1 for i in range(1000)]\n        f = open(os.path.join(HERE, 'files', 'ipac', 'string.txt'))\n        self.lines = f.read().split('\\n')\n        f.close()\n        self.table = ascii.read(os.path.join(HERE, 'files', 'ipac', 'string.txt'),\n                                format='ipac', guess=False)\n        self.reader = Ipac()\n        self.header = self.reader.header\n        self.data = self.reader.data\n        self.splitter = self.reader.data.splitter\n        self.header.cols = list(self.table.columns.values())\n        self.data.cols = list(self.table.columns.values())\n        self.data._set_fill_values(self.data.cols)",
        "min_run_count": 2,
        "name": "io_ascii.ipac.IPACSuite.time_data_str_vals",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8a3bdce4fcf48e81e8ce41f7a95624fa436aa50ff43ef6742ca6841c5a612078",
        "warmup_time": -1
    },
    "io_ascii.ipac.IPACSuite.time_get_cols": {
        "code": "class IPACSuite:\n    def time_get_cols(self):\n        self.header.get_cols(self.lines)\n\n    def setup(self):\n    \n        self.vals = [str(i + 1) for i in range(1000)]\n        self.widths = [i + 1 for i in range(1000)]\n        f = open(os.path.join(HERE, 'files', 'ipac', 'string.txt'))\n        self.lines = f.read().split('\\n')\n        f.close()\n        self.table = ascii.read(os.path.join(HERE, 'files', 'ipac', 'string.txt'),\n                                format='ipac', guess=False)\n        self.reader = Ipac()\n        self.header = self.reader.header\n        self.data = self.reader.data\n        self.splitter = self.reader.data.splitter\n        self.header.cols = list(self.table.columns.values())\n        self.data.cols = list(self.table.columns.values())\n        self.data._set_fill_values(self.data.cols)",
        "min_run_count": 2,
        "name": "io_ascii.ipac.IPACSuite.time_get_cols",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c905b1e6332762afc6abd89121edc86fc36facdd98ed210664104695bb4b097b",
        "warmup_time": -1
    },
    "io_ascii.ipac.IPACSuite.time_header_str_vals": {
        "code": "class IPACSuite:\n    def time_header_str_vals(self):\n        self.header.str_vals()\n\n    def setup(self):\n    \n        self.vals = [str(i + 1) for i in range(1000)]\n        self.widths = [i + 1 for i in range(1000)]\n        f = open(os.path.join(HERE, 'files', 'ipac', 'string.txt'))\n        self.lines = f.read().split('\\n')\n        f.close()\n        self.table = ascii.read(os.path.join(HERE, 'files', 'ipac', 'string.txt'),\n                                format='ipac', guess=False)\n        self.reader = Ipac()\n        self.header = self.reader.header\n        self.data = self.reader.data\n        self.splitter = self.reader.data.splitter\n        self.header.cols = list(self.table.columns.values())\n        self.data.cols = list(self.table.columns.values())\n        self.data._set_fill_values(self.data.cols)",
        "min_run_count": 2,
        "name": "io_ascii.ipac.IPACSuite.time_header_str_vals",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "439647016a26240060528ce9b7374314566ef65e627fcd04e61558d11ac3fdb7",
        "warmup_time": -1
    },
    "io_ascii.ipac.IPACSuite.time_splitter": {
        "code": "class IPACSuite:\n    def time_splitter(self):\n        self.splitter.join(self.vals, self.widths)\n\n    def setup(self):\n    \n        self.vals = [str(i + 1) for i in range(1000)]\n        self.widths = [i + 1 for i in range(1000)]\n        f = open(os.path.join(HERE, 'files', 'ipac', 'string.txt'))\n        self.lines = f.read().split('\\n')\n        f.close()\n        self.table = ascii.read(os.path.join(HERE, 'files', 'ipac', 'string.txt'),\n                                format='ipac', guess=False)\n        self.reader = Ipac()\n        self.header = self.reader.header\n        self.data = self.reader.data\n        self.splitter = self.reader.data.splitter\n        self.header.cols = list(self.table.columns.values())\n        self.data.cols = list(self.table.columns.values())\n        self.data._set_fill_values(self.data.cols)",
        "min_run_count": 2,
        "name": "io_ascii.ipac.IPACSuite.time_splitter",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a1bb23dfe8d83fee56ad9823654a874885f8c656ecbb4ce7c717c33d83183b62",
        "warmup_time": -1
    },
    "io_ascii.main.AastexFloat.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.AastexFloat.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.AastexFloat.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.AastexFloat.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.AastexInt.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.AastexInt.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.AastexInt.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.AastexInt.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.AastexString.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.AastexString.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.AastexString.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.AastexString.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.BasicFloat.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.BasicFloat.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.BasicFloat.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.BasicFloat.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.BasicInt.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.BasicInt.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.BasicInt.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.BasicInt.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.BasicString.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.BasicString.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.BasicString.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.BasicString.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.CommentedHeaderFloat.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.CommentedHeaderFloat.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.CommentedHeaderFloat.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.CommentedHeaderFloat.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.CommentedHeaderInt.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.CommentedHeaderInt.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.CommentedHeaderInt.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.CommentedHeaderInt.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.CommentedHeaderString.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.CommentedHeaderString.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.CommentedHeaderString.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.CommentedHeaderString.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.CsvFloat.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.CsvFloat.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.CsvFloat.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.CsvFloat.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.CsvInt.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.CsvInt.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.CsvInt.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.CsvInt.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.CsvString.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.CsvString.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.CsvString.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.CsvString.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthFloat.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthFloat.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthFloat.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthFloat.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthInt.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthInt.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthInt.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthInt.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthNoHeaderFloat.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthNoHeaderFloat.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthNoHeaderFloat.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthNoHeaderFloat.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthNoHeaderInt.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthNoHeaderInt.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthNoHeaderInt.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthNoHeaderInt.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthNoHeaderString.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthNoHeaderString.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthNoHeaderString.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthNoHeaderString.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthString.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthString.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthString.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthString.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthTwoLineFloat.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthTwoLineFloat.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthTwoLineFloat.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthTwoLineFloat.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthTwoLineInt.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthTwoLineInt.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthTwoLineInt.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthTwoLineInt.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthTwoLineString.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthTwoLineString.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.FixedWidthTwoLineString.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.FixedWidthTwoLineString.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.IpacFloat.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.IpacFloat.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.IpacFloat.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.IpacFloat.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.IpacInt.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.IpacInt.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.IpacInt.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.IpacInt.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.IpacString.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.IpacString.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.IpacString.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.IpacString.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.LatexFloat.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.LatexFloat.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.LatexFloat.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.LatexFloat.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.LatexInt.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.LatexInt.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.LatexInt.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.LatexInt.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.LatexString.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.LatexString.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.LatexString.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.LatexString.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.NoHeaderFloat.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.NoHeaderFloat.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.NoHeaderFloat.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.NoHeaderFloat.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.NoHeaderInt.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.NoHeaderInt.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.NoHeaderInt.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.NoHeaderInt.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.NoHeaderString.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.NoHeaderString.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.NoHeaderString.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.NoHeaderString.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.RdbFloat.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.RdbFloat.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.RdbFloat.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.RdbFloat.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.RdbInt.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.RdbInt.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.RdbInt.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.RdbInt.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.RdbString.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.RdbString.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.RdbString.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.RdbString.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.SextractorFloat.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.SextractorFloat.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.SextractorInt.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.SextractorInt.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.SextractorString.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.SextractorString.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.TabFloat.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.TabFloat.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.TabFloat.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.TabFloat.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.TabInt.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.TabInt.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.TabInt.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.TabInt.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.main.TabString.time_read": {
        "code": "class _ASCIISuite:\n    def read(self):\n        return ascii.read(BytesIO(self.data), format=self.file_format, guess=False)\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.TabString.time_read",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3f98728a95e3fb54e58199096d5d7673373a44c7a7043ed8f2a66f58abfdb20",
        "warmup_time": -1
    },
    "io_ascii.main.TabString.time_write": {
        "code": "class _ASCIISuite:\n    def write(self):\n        ascii.write(self.table, self.output, Writer=self.writers[self.file_format])\n\n    def setup(self):\n        self.tables = {}\n        self.data = {}\n        self.output = StringIO()\n        self.writers = {\n            'csv': ascii.Csv,\n            'rdb': ascii.Rdb,\n            'fixed_width': ascii.FixedWidth,\n            'fixed_width_no_header': ascii.FixedWidthNoHeader,\n            'fixed_width_two_line': ascii.FixedWidthTwoLine,\n            'tab': ascii.Tab,\n            'no_header': ascii.NoHeader,\n            'commented_header': ascii.CommentedHeader,\n            'basic': ascii.Basic,\n            'ipac': ascii.Ipac,\n            'latex': ascii.Latex,\n            'aastex': ascii.AASTex\n            }\n        with io.open(os.path.join(HERE, 'files', self.file_format, '{0}.txt'.format(self.data_type)), 'rb') as f:\n            self.data = f.read()\n        if self.file_format != 'sextractor':\n            self.table = self.read()",
        "min_run_count": 2,
        "name": "io_ascii.main.TabString.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "897cf90f396ada2768dcfb8082f28f799727fefdc591208d0cebb9ef67420754",
        "warmup_time": -1
    },
    "io_ascii.rdb.RDBSuite.time_get_cols": {
        "code": "class RDBSuite:\n    def time_get_cols(self):\n        self.header.get_cols(self.lines)\n\n    def setup(self):\n        self.header = basic.RdbHeader()\n        self.header.splitter.delimiter = '\\t'\n        f = open(os.path.join(HERE,'files','rdb', 'string.txt'))\n        self.lines = f.read().split('\\n')\n        f.close()",
        "min_run_count": 2,
        "name": "io_ascii.rdb.RDBSuite.time_get_cols",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "37775e9215e57ff1ba0ec99edd94cbc2a293a129a551ed55f92e669007bad661",
        "warmup_time": -1
    },
    "io_ascii.sextractor.SExtractorSuite.time_header": {
        "code": "class SExtractorSuite:\n    def time_header(self):\n        self.header.get_cols(self.lines)\n\n    def setup(self):\n        self.header = sextractor.SExtractorHeader()\n        self.lines = []\n        i = 0\n        while i < 100000:\n            if i % 20 == 0 and i != 0:\n                i += 4\n            i += 1\n            self.lines.append('# {} {} Description [pixel**2]'.format(\n                                                        i, randword()))\n        self.lines.append('Non-header line')",
        "min_run_count": 2,
        "name": "io_ascii.sextractor.SExtractorSuite.time_header",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a9db4d189763ff1473f14cb8d568fbe618facb3d376edc5a200bf69eefc7a110",
        "warmup_time": -1
    },
    "io_ascii.table.TableSuite.mem_table_init": {
        "code": "class TableSuite:\n    def mem_table_init(self):\n        return table.Table(self.lst)\n\n    def setup(self):\n        self.lst = []\n        self.lst.append([random.randint(-500, 500) for i in range(1000)])\n        self.lst.append([random.random() * 500 - 500 for i in range(1000)])\n        self.lst.append([''.join([random.choice(uppercase) for j in\n                            range(6)]) for i in range(1000)])\n        self.cols = [core.Column(str(i + 1)) for i in range(3)]\n        for col, x in izip(self.cols, self.lst):\n            col.data = x\n        self.table_cols = [table.Column(x) for x in self.lst]\n        self.outputter = core.TableOutputter()\n        self.table = table.Table()",
        "name": "io_ascii.table.TableSuite.mem_table_init",
        "param_names": [],
        "params": [],
        "timeout": 60.0,
        "type": "memory",
        "unit": "bytes",
        "version": "f93dd63923309c0a3643cbc5565c4081d6525256c63f4845d5f94ba6e4ea0bd6"
    },
    "io_ascii.table.TableSuite.mem_table_outputter": {
        "code": "class TableSuite:\n    def mem_table_outputter(self):\n        return self.outputter(self.cols, {'table': {}})\n\n    def setup(self):\n        self.lst = []\n        self.lst.append([random.randint(-500, 500) for i in range(1000)])\n        self.lst.append([random.random() * 500 - 500 for i in range(1000)])\n        self.lst.append([''.join([random.choice(uppercase) for j in\n                            range(6)]) for i in range(1000)])\n        self.cols = [core.Column(str(i + 1)) for i in range(3)]\n        for col, x in izip(self.cols, self.lst):\n            col.data = x\n        self.table_cols = [table.Column(x) for x in self.lst]\n        self.outputter = core.TableOutputter()\n        self.table = table.Table()",
        "name": "io_ascii.table.TableSuite.mem_table_outputter",
        "param_names": [],
        "params": [],
        "timeout": 60.0,
        "type": "memory",
        "unit": "bytes",
        "version": "0ee6f7a393d03abd1ac6cdfa55936a4462adde546042fddc5ba7189476e0507b"
    },
    "io_ascii.table.TableSuite.time_str_vals_float": {
        "code": "class TableSuite:\n    def time_str_vals_float(self):\n        self.table_cols[1].iter_str_vals()\n\n    def setup(self):\n        self.lst = []\n        self.lst.append([random.randint(-500, 500) for i in range(1000)])\n        self.lst.append([random.random() * 500 - 500 for i in range(1000)])\n        self.lst.append([''.join([random.choice(uppercase) for j in\n                            range(6)]) for i in range(1000)])\n        self.cols = [core.Column(str(i + 1)) for i in range(3)]\n        for col, x in izip(self.cols, self.lst):\n            col.data = x\n        self.table_cols = [table.Column(x) for x in self.lst]\n        self.outputter = core.TableOutputter()\n        self.table = table.Table()",
        "min_run_count": 2,
        "name": "io_ascii.table.TableSuite.time_str_vals_float",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2d818883f1301a824cb3809cdc36587446e6edba5a2fcb67f00410e94f731669",
        "warmup_time": -1
    },
    "io_ascii.table.TableSuite.time_str_vals_int": {
        "code": "class TableSuite:\n    def time_str_vals_int(self):\n        self.table_cols[0].iter_str_vals()\n\n    def setup(self):\n        self.lst = []\n        self.lst.append([random.randint(-500, 500) for i in range(1000)])\n        self.lst.append([random.random() * 500 - 500 for i in range(1000)])\n        self.lst.append([''.join([random.choice(uppercase) for j in\n                            range(6)]) for i in range(1000)])\n        self.cols = [core.Column(str(i + 1)) for i in range(3)]\n        for col, x in izip(self.cols, self.lst):\n            col.data = x\n        self.table_cols = [table.Column(x) for x in self.lst]\n        self.outputter = core.TableOutputter()\n        self.table = table.Table()",
        "min_run_count": 2,
        "name": "io_ascii.table.TableSuite.time_str_vals_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9109ab1ddedde92cafdb2a0644f73936b59cd52b967369db71cbf0532cd65d46",
        "warmup_time": -1
    },
    "io_ascii.table.TableSuite.time_str_vals_str": {
        "code": "class TableSuite:\n    def time_str_vals_str(self):\n        self.table_cols[2].iter_str_vals()\n\n    def setup(self):\n        self.lst = []\n        self.lst.append([random.randint(-500, 500) for i in range(1000)])\n        self.lst.append([random.random() * 500 - 500 for i in range(1000)])\n        self.lst.append([''.join([random.choice(uppercase) for j in\n                            range(6)]) for i in range(1000)])\n        self.cols = [core.Column(str(i + 1)) for i in range(3)]\n        for col, x in izip(self.cols, self.lst):\n            col.data = x\n        self.table_cols = [table.Column(x) for x in self.lst]\n        self.outputter = core.TableOutputter()\n        self.table = table.Table()",
        "min_run_count": 2,
        "name": "io_ascii.table.TableSuite.time_str_vals_str",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "854ab35dbba7720bbe4729cc5ca9aaf04d856af1f4e0d32f1c7c7504f29a46f8",
        "warmup_time": -1
    },
    "io_ascii.table.TableSuite.time_table_init_from_list": {
        "code": "class TableSuite:\n    def time_table_init_from_list(self):\n        self.table._init_from_list(self.table_cols, ['1', '2', '3'],\n                                   [None, None, None], 3, True)\n\n    def setup(self):\n        self.lst = []\n        self.lst.append([random.randint(-500, 500) for i in range(1000)])\n        self.lst.append([random.random() * 500 - 500 for i in range(1000)])\n        self.lst.append([''.join([random.choice(uppercase) for j in\n                            range(6)]) for i in range(1000)])\n        self.cols = [core.Column(str(i + 1)) for i in range(3)]\n        for col, x in izip(self.cols, self.lst):\n            col.data = x\n        self.table_cols = [table.Column(x) for x in self.lst]\n        self.outputter = core.TableOutputter()\n        self.table = table.Table()",
        "min_run_count": 2,
        "name": "io_ascii.table.TableSuite.time_table_init_from_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ebc1f5751e08f92ba669a08cb5144ce1c72d750daf659f9e933b18c5fcf92d69",
        "warmup_time": -1
    },
    "io_ascii.table.TableSuite.time_table_outputter": {
        "code": "class TableSuite:\n    def time_table_outputter(self):\n        self.outputter(self.cols, {'table': {}})\n\n    def setup(self):\n        self.lst = []\n        self.lst.append([random.randint(-500, 500) for i in range(1000)])\n        self.lst.append([random.random() * 500 - 500 for i in range(1000)])\n        self.lst.append([''.join([random.choice(uppercase) for j in\n                            range(6)]) for i in range(1000)])\n        self.cols = [core.Column(str(i + 1)) for i in range(3)]\n        for col, x in izip(self.cols, self.lst):\n            col.data = x\n        self.table_cols = [table.Column(x) for x in self.lst]\n        self.outputter = core.TableOutputter()\n        self.table = table.Table()",
        "min_run_count": 2,
        "name": "io_ascii.table.TableSuite.time_table_outputter",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c9cda8c5462696d451d132a464ef7a0319161924c36a82031904e8c6a0b7fd9b",
        "warmup_time": -1
    },
    "io_fits.FITSBinTableHDU.time_from_columns_bytes": {
        "code": "class FITSBinTableHDU:\n    def time_from_columns_bytes(self):\n        x = np.repeat(b'a', 2_000_000)\n        array = np.array(x, dtype=[('col', 'S1')])\n        fits.BinTableHDU.from_columns(array)",
        "min_run_count": 2,
        "name": "io_fits.FITSBinTableHDU.time_from_columns_bytes",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "873e9f809455ab1378f9d5ea753e35754337626c1f958069b5d9ff333e42cf1e",
        "warmup_time": -1
    },
    "io_fits.FITSHDUList.time_getheader": {
        "code": "class FITSHDUList:\n    def time_getheader(self):\n        fits.getheader(self.filename)\n\n    def setup(self):\n        self.filename = mktemp(suffix='.fits')\n        hdr = make_header()\n        hdul = fits.HDUList([fits.PrimaryHDU(header=hdr)] +\n                            [fits.ImageHDU(header=hdr) for _ in range(100)])\n        hdul.writeto(self.filename)",
        "min_run_count": 2,
        "name": "io_fits.FITSHDUList.time_getheader",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2b10fbd9014d50df6fc31532c80019ac2cd43344bad3d014deb1ba89cb54d10e",
        "warmup_time": -1
    },
    "io_fits.FITSHDUList.time_getheader_ext50": {
        "code": "class FITSHDUList:\n    def time_getheader_ext50(self):\n        fits.getheader(self.filename, ext=50)\n\n    def setup(self):\n        self.filename = mktemp(suffix='.fits')\n        hdr = make_header()\n        hdul = fits.HDUList([fits.PrimaryHDU(header=hdr)] +\n                            [fits.ImageHDU(header=hdr) for _ in range(100)])\n        hdul.writeto(self.filename)",
        "min_run_count": 2,
        "name": "io_fits.FITSHDUList.time_getheader_ext50",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9a79c0eec8e2a2a7a7768d3115acb62cf1a61b744727f28a3bc963533c081cd9",
        "warmup_time": -1
    },
    "io_fits.FITSHDUList.time_len": {
        "code": "class FITSHDUList:\n    def time_len(self):\n        with fits.open(self.filename) as hdul:\n            len(hdul)\n\n    def setup(self):\n        self.filename = mktemp(suffix='.fits')\n        hdr = make_header()\n        hdul = fits.HDUList([fits.PrimaryHDU(header=hdr)] +\n                            [fits.ImageHDU(header=hdr) for _ in range(100)])\n        hdul.writeto(self.filename)",
        "min_run_count": 2,
        "name": "io_fits.FITSHDUList.time_len",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "661135181dc1bed6e74a097f2bf82ba156c33fd948bab92fb7220c4e950fb507",
        "warmup_time": -1
    },
    "io_fits.FITSHeader.time_fromstring": {
        "code": "class FITSHeader:\n    def time_fromstring(self):\n        fits.Header.fromstring(self.hdr_string)\n\n    def setup(self):\n        self.hdr = make_header()\n        self.hdr_string = self.hdr.tostring()",
        "min_run_count": 2,
        "name": "io_fits.FITSHeader.time_fromstring",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3234919da8be45519bcc25b55e86b4bc89cff61c0a0d392ee9580b7b4fe5e423",
        "warmup_time": -1
    },
    "io_fits.FITSHeader.time_get_float": {
        "code": "class FITSHeader:\n    def time_get_float(self):\n        self.hdr.get('FLT999')\n\n    def setup(self):\n        self.hdr = make_header()\n        self.hdr_string = self.hdr.tostring()",
        "min_run_count": 2,
        "name": "io_fits.FITSHeader.time_get_float",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "00ab909c46d9216d744cf820f83dd46ddad909a3b5908a1beaf69196f754e429",
        "warmup_time": -1
    },
    "io_fits.FITSHeader.time_get_hierarch": {
        "code": "class FITSHeader:\n    def time_get_hierarch(self):\n        self.hdr.get('HIERARCH FOO BAR 999')\n\n    def setup(self):\n        self.hdr = make_header()\n        self.hdr_string = self.hdr.tostring()",
        "min_run_count": 2,
        "name": "io_fits.FITSHeader.time_get_hierarch",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1bde7a3abb0d3d81239c9f9f3b61cb8b91f1e641c59d9daf64bcdd138f3f20e7",
        "warmup_time": -1
    },
    "io_fits.FITSHeader.time_get_int": {
        "code": "class FITSHeader:\n    def time_get_int(self):\n        self.hdr.get('INT999')\n\n    def setup(self):\n        self.hdr = make_header()\n        self.hdr_string = self.hdr.tostring()",
        "min_run_count": 2,
        "name": "io_fits.FITSHeader.time_get_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0f838a0e87478d8113791bd9b2c77332784ec2ada47ec50a22d5d255b6aa6625",
        "warmup_time": -1
    },
    "io_fits.FITSHeader.time_get_str": {
        "code": "class FITSHeader:\n    def time_get_str(self):\n        self.hdr.get('STR999')\n\n    def setup(self):\n        self.hdr = make_header()\n        self.hdr_string = self.hdr.tostring()",
        "min_run_count": 2,
        "name": "io_fits.FITSHeader.time_get_str",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b2891d9b4b836d96029cecba62ce013d75ab97114584edaa466fb86b8aa1b22e",
        "warmup_time": -1
    },
    "io_fits.FITSHeader.time_tostring": {
        "code": "class FITSHeader:\n    def time_tostring(self):\n        self.hdr.tostring()\n\n    def setup(self):\n        self.hdr = make_header()\n        self.hdr_string = self.hdr.tostring()",
        "min_run_count": 2,
        "name": "io_fits.FITSHeader.time_tostring",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fc00e8adbf6c0b6afe47b9d61f9448c6161b2d508412b3c05f82d14a27aea1fa",
        "warmup_time": -1
    },
    "io_fits.FITSHighLevelTableBenchmarks.time_read_nommap": {
        "code": "class FITSHighLevelTableBenchmarks:\n    def time_read_nommap(self):\n        self.table_bytes.seek(0)\n        try:\n            Table.read(self.table_bytes, format='fits', memmap=False)\n        except TypeError:\n            Table.read(self.table_bytes, format='fits')\n\n    def setup(self):\n    \n        N = 2_000_000\n    \n        self.table_bytes = BytesIO()\n    \n        t = Table()\n        t['floats'] = np.random.random(N)\n        t['ints'] = np.random.randint(0, 100, N)\n        t['strings'] = b'some strings'\n        t['booleans'] = t['floats'] > 0.5\n        t.write(self.table_bytes, format='fits')",
        "min_run_count": 2,
        "name": "io_fits.FITSHighLevelTableBenchmarks.time_read_nommap",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "aad5f871ef8603c05f0a64ae405c585e95d081798cb3576da10a6bd73d17d3bf",
        "warmup_time": -1
    },
    "io_fits.FITSHighLevelTableBenchmarks.time_write": {
        "code": "class FITSHighLevelTableBenchmarks:\n    def time_write(self):\n        N = 1_000_000\n        table_bytes = BytesIO()\n        t = Table()\n        t['floats'] = np.random.random(N)\n        t['ints'] = np.random.randint(0, 100, N)\n        t['strings'] = b'some strings'\n        t['booleans'] = t['floats'] > 0.5\n        t.write(table_bytes, format='fits')\n\n    def setup(self):\n    \n        N = 2_000_000\n    \n        self.table_bytes = BytesIO()\n    \n        t = Table()\n        t['floats'] = np.random.random(N)\n        t['ints'] = np.random.randint(0, 100, N)\n        t['strings'] = b'some strings'\n        t['booleans'] = t['floats'] > 0.5\n        t.write(self.table_bytes, format='fits')",
        "min_run_count": 2,
        "name": "io_fits.FITSHighLevelTableBenchmarks.time_write",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "dbe7f96c19284a4c494c1f35313cd7f12a367d222c3dffb9c45dab2372722556",
        "warmup_time": -1
    },
    "modeling.compound.EvaluateCompoundModelNoUnits.time_large": {
        "code": "class EvaluateCompoundModelNoUnits:\n    def time_large(self):\n        r, d = self.model(x_no_units_large, x_no_units_large)\n\n    def setup(self):\n        aff = models.AffineTransformation2D(matrix=[[1, 0], [0, 1]],\n                                            translation=[0, 0])\n        self.model = (models.Shift(-10.5) & models.Shift(-13.2) | aff |\n                      models.Scale(.01) & models.Scale(.04) |\n                      models.Pix2Sky_TAN() |\n                      models.RotateNative2Celestial(5.6, -72.05, 180))",
        "min_run_count": 2,
        "name": "modeling.compound.EvaluateCompoundModelNoUnits.time_large",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b0b54635b710091fe552e9c8d487ac25f4a06ea807f2e29900f3617936734098",
        "warmup_time": -1
    },
    "modeling.compound.EvaluateCompoundModelNoUnits.time_medium": {
        "code": "class EvaluateCompoundModelNoUnits:\n    def time_medium(self):\n        r, d = self.model(x_no_units_medium, x_no_units_medium)\n\n    def setup(self):\n        aff = models.AffineTransformation2D(matrix=[[1, 0], [0, 1]],\n                                            translation=[0, 0])\n        self.model = (models.Shift(-10.5) & models.Shift(-13.2) | aff |\n                      models.Scale(.01) & models.Scale(.04) |\n                      models.Pix2Sky_TAN() |\n                      models.RotateNative2Celestial(5.6, -72.05, 180))",
        "min_run_count": 2,
        "name": "modeling.compound.EvaluateCompoundModelNoUnits.time_medium",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "40c307032c7136668a9ddda782ee13b2df5c0c617ce00b393404817c2d0a7f17",
        "warmup_time": -1
    },
    "modeling.compound.EvaluateCompoundModelNoUnits.time_scalar": {
        "code": "class EvaluateCompoundModelNoUnits:\n    def time_scalar(self):\n        r, d = self.model(x_no_units_scalar, x_no_units_scalar)\n\n    def setup(self):\n        aff = models.AffineTransformation2D(matrix=[[1, 0], [0, 1]],\n                                            translation=[0, 0])\n        self.model = (models.Shift(-10.5) & models.Shift(-13.2) | aff |\n                      models.Scale(.01) & models.Scale(.04) |\n                      models.Pix2Sky_TAN() |\n                      models.RotateNative2Celestial(5.6, -72.05, 180))",
        "min_run_count": 2,
        "name": "modeling.compound.EvaluateCompoundModelNoUnits.time_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5865ce2892767c224db72612384f7f634a7ff8103577fc57e5d123fc2abb456b",
        "warmup_time": -1
    },
    "modeling.compound.EvaluateCompoundModelNoUnits.time_small": {
        "code": "class EvaluateCompoundModelNoUnits:\n    def time_small(self):\n        r, d = self.model(x_no_units_small, x_no_units_small)\n\n    def setup(self):\n        aff = models.AffineTransformation2D(matrix=[[1, 0], [0, 1]],\n                                            translation=[0, 0])\n        self.model = (models.Shift(-10.5) & models.Shift(-13.2) | aff |\n                      models.Scale(.01) & models.Scale(.04) |\n                      models.Pix2Sky_TAN() |\n                      models.RotateNative2Celestial(5.6, -72.05, 180))",
        "min_run_count": 2,
        "name": "modeling.compound.EvaluateCompoundModelNoUnits.time_small",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "309255930235db8eaf1ecfae1930a00f9cac32cb7ec324bb83907e2062ecdbc0",
        "warmup_time": -1
    },
    "modeling.compound.EvaluateCompoundModelWithUnits.time_large": {
        "code": "class EvaluateCompoundModelWithUnits:\n    def time_large(self):\n        r, d, = self.model(x_no_units_large * u.pix, x_no_units_large * u.pix)\n\n    def setup(self):\n        aff = models.AffineTransformation2D(matrix=[[1, 0], [0, 1]] * u.arcsec,\n                                            translation=[0, 0] * u.arcsec)\n        aff.input_units_equivalencies = {'x': u.pixel_scale(1 * u.arcsec/u.pix),\n                                         'y': u.pixel_scale(1 * u.arcsec/u.pix)}\n        self.model = (models.Shift(-10.5 * u.pix) & models.Shift(-13.2 * u.pix) |\n                      aff |\n                      models.Scale(.01 * u.arcsec) & models.Scale(.04 * u.deg) |\n                      models.Pix2Sky_TAN() |\n                      models.RotateNative2Celestial(5.6 * u.deg, -72.05 * u.deg, 180 * u.deg))",
        "min_run_count": 2,
        "name": "modeling.compound.EvaluateCompoundModelWithUnits.time_large",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5364c034b6eefa53fb576633d90cf05d3f2825c37a53c5a94df95476e6667a31",
        "warmup_time": -1
    },
    "modeling.compound.EvaluateCompoundModelWithUnits.time_medium": {
        "code": "class EvaluateCompoundModelWithUnits:\n    def time_medium(self):\n        r, d = self.model(x_no_units_medium * u.pix, x_no_units_medium * u.pix)\n\n    def setup(self):\n        aff = models.AffineTransformation2D(matrix=[[1, 0], [0, 1]] * u.arcsec,\n                                            translation=[0, 0] * u.arcsec)\n        aff.input_units_equivalencies = {'x': u.pixel_scale(1 * u.arcsec/u.pix),\n                                         'y': u.pixel_scale(1 * u.arcsec/u.pix)}\n        self.model = (models.Shift(-10.5 * u.pix) & models.Shift(-13.2 * u.pix) |\n                      aff |\n                      models.Scale(.01 * u.arcsec) & models.Scale(.04 * u.deg) |\n                      models.Pix2Sky_TAN() |\n                      models.RotateNative2Celestial(5.6 * u.deg, -72.05 * u.deg, 180 * u.deg))",
        "min_run_count": 2,
        "name": "modeling.compound.EvaluateCompoundModelWithUnits.time_medium",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6816e68192af9eb03284ab4e411de1b4f9ea3b3289376be3effc272ade0dcc07",
        "warmup_time": -1
    },
    "modeling.compound.EvaluateCompoundModelWithUnits.time_scalar": {
        "code": "class EvaluateCompoundModelWithUnits:\n    def time_scalar(self):\n        r, d = self.model(x_no_units_scalar * u.pix, x_no_units_scalar * u.pix)\n\n    def setup(self):\n        aff = models.AffineTransformation2D(matrix=[[1, 0], [0, 1]] * u.arcsec,\n                                            translation=[0, 0] * u.arcsec)\n        aff.input_units_equivalencies = {'x': u.pixel_scale(1 * u.arcsec/u.pix),\n                                         'y': u.pixel_scale(1 * u.arcsec/u.pix)}\n        self.model = (models.Shift(-10.5 * u.pix) & models.Shift(-13.2 * u.pix) |\n                      aff |\n                      models.Scale(.01 * u.arcsec) & models.Scale(.04 * u.deg) |\n                      models.Pix2Sky_TAN() |\n                      models.RotateNative2Celestial(5.6 * u.deg, -72.05 * u.deg, 180 * u.deg))",
        "min_run_count": 2,
        "name": "modeling.compound.EvaluateCompoundModelWithUnits.time_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "175be523c850767a6955554517b737160aab5af7ce4ef4314e55ee1bbfa479c1",
        "warmup_time": -1
    },
    "modeling.compound.EvaluateCompoundModelWithUnits.time_small": {
        "code": "class EvaluateCompoundModelWithUnits:\n    def time_small(self):\n        r, d = self.model(x_no_units_small * u.pix, x_no_units_small * u.pix)\n\n    def setup(self):\n        aff = models.AffineTransformation2D(matrix=[[1, 0], [0, 1]] * u.arcsec,\n                                            translation=[0, 0] * u.arcsec)\n        aff.input_units_equivalencies = {'x': u.pixel_scale(1 * u.arcsec/u.pix),\n                                         'y': u.pixel_scale(1 * u.arcsec/u.pix)}\n        self.model = (models.Shift(-10.5 * u.pix) & models.Shift(-13.2 * u.pix) |\n                      aff |\n                      models.Scale(.01 * u.arcsec) & models.Scale(.04 * u.deg) |\n                      models.Pix2Sky_TAN() |\n                      models.RotateNative2Celestial(5.6 * u.deg, -72.05 * u.deg, 180 * u.deg))",
        "min_run_count": 2,
        "name": "modeling.compound.EvaluateCompoundModelWithUnits.time_small",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "390fa00a83cf134f0e2732d1ebb8b4bfa923f434780b5459a30b3995cf6c78c8",
        "warmup_time": -1
    },
    "modeling.compound.time_init_7_no_units": {
        "code": "def time_init_7_no_units():\n    m = (models.Shift(-10.5) & models.Shift(-13.2) |\n         models.AffineTransformation2D(matrix=[[1, 0], [0, 1]],\n                                       translation=[0, 0]) |\n         models.Scale(.01) & models.Scale(.04) |\n         models.Pix2Sky_TAN() |\n         models.RotateNative2Celestial(5.6, -72.05, 180))",
        "min_run_count": 2,
        "name": "modeling.compound.time_init_7_no_units",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4a2d487b68969ae27d31520ae521f05d6d10a2deda289fc4e5bf61883c77bdea",
        "warmup_time": -1
    },
    "modeling.compound.time_init_7_with_units": {
        "code": "def time_init_7_with_units():\n    aff = models.AffineTransformation2D(matrix=[[1, 0], [0, 1]]*u.arcsec,\n                                        translation=[0, 0]*u.arcsec)\n    aff.input_units_equivalencies = {'x': u.pixel_scale(1*u.arcsec/u.pix),\n                                     'y': u.pixel_scale(1*u.arcsec/u.pix)}\n    m = (models.Shift(-10.5*u.pix) & models.Shift(-13.2*u.pix) |\n         aff |\n         models.Scale(.01*u.arcsec) & models.Scale(.04*u.arcsec) |\n         models.Pix2Sky_TAN() |\n         models.RotateNative2Celestial(5.6*u.deg, -72.05*u.deg, 180*u.deg))",
        "min_run_count": 2,
        "name": "modeling.compound.time_init_7_with_units",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5194af61b5c0a0ba6f991a39016d1cb8da891c7057229cccf12647453c12a52f",
        "warmup_time": -1
    },
    "modeling.model.time_eval_gaussian_no_units_large": {
        "code": "def time_eval_gaussian_no_units_large():\n    gauss1d_no_units(x_no_units_large)",
        "min_run_count": 2,
        "name": "modeling.model.time_eval_gaussian_no_units_large",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0745d6e26390ea0955fb70202a940a8ced4a63de8711157fe7c61c3319f6dce2",
        "warmup_time": -1
    },
    "modeling.model.time_eval_gaussian_no_units_medium": {
        "code": "def time_eval_gaussian_no_units_medium():\n    gauss1d_no_units(x_no_units_medium)",
        "min_run_count": 2,
        "name": "modeling.model.time_eval_gaussian_no_units_medium",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b00f3b9d88de9c4dbb454e4c3dbba6cb899df7f5e2f7653bd4667e84a5d1e04b",
        "warmup_time": -1
    },
    "modeling.model.time_eval_gaussian_no_units_scalar": {
        "code": "def time_eval_gaussian_no_units_scalar():\n    gauss1d_no_units(x_no_units_scalar)",
        "min_run_count": 2,
        "name": "modeling.model.time_eval_gaussian_no_units_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "653ea162dbc19cb18713d9808efa58a2578649c92b88219d87a453a6f61fd160",
        "warmup_time": -1
    },
    "modeling.model.time_eval_gaussian_no_units_small": {
        "code": "def time_eval_gaussian_no_units_small():\n    gauss1d_no_units(x_no_units_small)",
        "min_run_count": 2,
        "name": "modeling.model.time_eval_gaussian_no_units_small",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0fb916a3251138dabe2c8c5c69502708d508f63e38d44556b66af28cde0d392f",
        "warmup_time": -1
    },
    "modeling.model.time_eval_gaussian_with_units_large": {
        "code": "def time_eval_gaussian_with_units_large():\n    gauss1d_with_units(x_with_units_large)",
        "min_run_count": 2,
        "name": "modeling.model.time_eval_gaussian_with_units_large",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a7240dbecfcacf55d8dc44b63f20dacde4e63314360f02214f4d34a2258333f8",
        "warmup_time": -1
    },
    "modeling.model.time_eval_gaussian_with_units_medium": {
        "code": "def time_eval_gaussian_with_units_medium():\n    gauss1d_with_units(x_with_units_medium)",
        "min_run_count": 2,
        "name": "modeling.model.time_eval_gaussian_with_units_medium",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "738ab4ddc951739727f5f86421d59fb06c1adbf63625ba97405bb344c0b13d52",
        "warmup_time": -1
    },
    "modeling.model.time_eval_gaussian_with_units_scalar": {
        "code": "def time_eval_gaussian_with_units_scalar():\n    gauss1d_with_units(x_with_units_scalar)",
        "min_run_count": 2,
        "name": "modeling.model.time_eval_gaussian_with_units_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "67d547c82e36ecb2493e01fa9103c858a5c4f8594af171283e7059adfa5aec6a",
        "warmup_time": -1
    },
    "modeling.model.time_eval_gaussian_with_units_small": {
        "code": "def time_eval_gaussian_with_units_small():\n    gauss1d_with_units(x_with_units_small)",
        "min_run_count": 2,
        "name": "modeling.model.time_eval_gaussian_with_units_small",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4f5d3b9c6646246e2765043aab70cbc989c22f842f584e3f19440f155c09cce0",
        "warmup_time": -1
    },
    "modeling.model.time_init_gaussian_no_units": {
        "code": "def time_init_gaussian_no_units():\n    m = models.Gaussian1D(amplitude=10, mean=5, stddev=1.2)",
        "min_run_count": 2,
        "name": "modeling.model.time_init_gaussian_no_units",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fb5b1807c0e36c07723044807503ec1302e43b43301e354588442e20acccec08",
        "warmup_time": -1
    },
    "modeling.model.time_init_gaussian_with_units": {
        "code": "def time_init_gaussian_with_units():\n    m = models.Gaussian1D(amplitude=10*u.Hz, mean=5*u.m, stddev=1.2*u.cm)",
        "min_run_count": 2,
        "name": "modeling.model.time_init_gaussian_with_units",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "597db77b9b34f83f9c1301599cfeb315e09bbe723c08823ccf08846fddf4abde",
        "warmup_time": -1
    },
    "modeling.model.time_model_init": {
        "code": "def time_model_init():\n    m = models.Shift(2)",
        "min_run_count": 2,
        "name": "modeling.model.time_model_init",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2669025669e382f24d826cb361d24077a1fe96fbafe6e98796183b264852daca",
        "warmup_time": -1
    },
    "modeling.model.time_model_init_2": {
        "code": "def time_model_init_2():\n    m = models.Polynomial1D(1, c0=.2, c1=3.4)",
        "min_run_count": 2,
        "name": "modeling.model.time_model_init_2",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8f72659af23424194565aaab5cd4f4343611040123ea19cf092d0b2dec7e9127",
        "warmup_time": -1
    },
    "stats.sigma_clipping.SigmaClipBenchmarks.time_1d_array": {
        "code": "class SigmaClipBenchmarks:\n    def time_1d_array(self):\n        self.sigclip(self.data[0][0])\n\n    def setup(self):\n    \n        # Avoid top-level module import to make sure that the benchmarks are\n        # compatible with versions of astropy that did not have this functionality.\n        from astropy.stats import SigmaClip\n    \n        size = (4, 2048, 2048)\n    \n        with NumpyRNGContext(12345):\n            self.data = np.random.normal(size=size)\n    \n            # add outliers\n            nbad = 100000\n            zbad = np.random.randint(low=0, high=size[0] - 1, size=nbad)\n            ybad = np.random.randint(low=0, high=size[1] - 1, size=nbad)\n            xbad = np.random.randint(low=0, high=size[2] - 1, size=nbad)\n            self.data[zbad, ybad, xbad] = (\n                np.random.choice([-1, 1], size=nbad) *\n                (10 + np.random.rand(nbad)))\n    \n            # The defaults use median as the cenfunc and standard\n            # deviation as the stdfunc.  The default iters is 5.\n            self.sigclip = SigmaClip(sigma=3)",
        "min_run_count": 2,
        "name": "stats.sigma_clipping.SigmaClipBenchmarks.time_1d_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fc10dcb1e6aaa111da09c12756b194db50d44ba21749f639852c5003c7250f8d",
        "warmup_time": -1
    },
    "stats.sigma_clipping.SigmaClipBenchmarks.time_2d_array": {
        "code": "class SigmaClipBenchmarks:\n    def time_2d_array(self):\n        self.sigclip(self.data[0])\n\n    def setup(self):\n    \n        # Avoid top-level module import to make sure that the benchmarks are\n        # compatible with versions of astropy that did not have this functionality.\n        from astropy.stats import SigmaClip\n    \n        size = (4, 2048, 2048)\n    \n        with NumpyRNGContext(12345):\n            self.data = np.random.normal(size=size)\n    \n            # add outliers\n            nbad = 100000\n            zbad = np.random.randint(low=0, high=size[0] - 1, size=nbad)\n            ybad = np.random.randint(low=0, high=size[1] - 1, size=nbad)\n            xbad = np.random.randint(low=0, high=size[2] - 1, size=nbad)\n            self.data[zbad, ybad, xbad] = (\n                np.random.choice([-1, 1], size=nbad) *\n                (10 + np.random.rand(nbad)))\n    \n            # The defaults use median as the cenfunc and standard\n            # deviation as the stdfunc.  The default iters is 5.\n            self.sigclip = SigmaClip(sigma=3)",
        "min_run_count": 2,
        "name": "stats.sigma_clipping.SigmaClipBenchmarks.time_2d_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "df7e384e9a766e38bbb10a01cf468e213e36f8f4a5ba6a93b1cdadb1fe5f371f",
        "warmup_time": -1
    },
    "stats.sigma_clipping.SigmaClipBenchmarks.time_2d_array_axis": {
        "code": "class SigmaClipBenchmarks:\n    def time_2d_array_axis(self):\n        self.sigclip(self.data[0], axis=0)\n\n    def setup(self):\n    \n        # Avoid top-level module import to make sure that the benchmarks are\n        # compatible with versions of astropy that did not have this functionality.\n        from astropy.stats import SigmaClip\n    \n        size = (4, 2048, 2048)\n    \n        with NumpyRNGContext(12345):\n            self.data = np.random.normal(size=size)\n    \n            # add outliers\n            nbad = 100000\n            zbad = np.random.randint(low=0, high=size[0] - 1, size=nbad)\n            ybad = np.random.randint(low=0, high=size[1] - 1, size=nbad)\n            xbad = np.random.randint(low=0, high=size[2] - 1, size=nbad)\n            self.data[zbad, ybad, xbad] = (\n                np.random.choice([-1, 1], size=nbad) *\n                (10 + np.random.rand(nbad)))\n    \n            # The defaults use median as the cenfunc and standard\n            # deviation as the stdfunc.  The default iters is 5.\n            self.sigclip = SigmaClip(sigma=3)",
        "min_run_count": 2,
        "name": "stats.sigma_clipping.SigmaClipBenchmarks.time_2d_array_axis",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "934258e9d1d54ed0653d2bebdc509652435fe618539825b741f2d7f7792e7155",
        "warmup_time": -1
    },
    "stats.sigma_clipping.SigmaClipBenchmarks.time_3d_array": {
        "code": "class SigmaClipBenchmarks:\n    def time_3d_array(self):\n        self.sigclip(self.data[:, :1024, :1024])\n\n    def setup(self):\n    \n        # Avoid top-level module import to make sure that the benchmarks are\n        # compatible with versions of astropy that did not have this functionality.\n        from astropy.stats import SigmaClip\n    \n        size = (4, 2048, 2048)\n    \n        with NumpyRNGContext(12345):\n            self.data = np.random.normal(size=size)\n    \n            # add outliers\n            nbad = 100000\n            zbad = np.random.randint(low=0, high=size[0] - 1, size=nbad)\n            ybad = np.random.randint(low=0, high=size[1] - 1, size=nbad)\n            xbad = np.random.randint(low=0, high=size[2] - 1, size=nbad)\n            self.data[zbad, ybad, xbad] = (\n                np.random.choice([-1, 1], size=nbad) *\n                (10 + np.random.rand(nbad)))\n    \n            # The defaults use median as the cenfunc and standard\n            # deviation as the stdfunc.  The default iters is 5.\n            self.sigclip = SigmaClip(sigma=3)",
        "min_run_count": 2,
        "name": "stats.sigma_clipping.SigmaClipBenchmarks.time_3d_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d23bebeb3489537d166c6da312564f1ed6e3651112789e056404f0db68f98896",
        "warmup_time": -1
    },
    "stats.sigma_clipping.SigmaClipBenchmarks.time_3d_array_axis": {
        "code": "class SigmaClipBenchmarks:\n    def time_3d_array_axis(self):\n        self.sigclip(self.data, axis=0)\n\n    def setup(self):\n    \n        # Avoid top-level module import to make sure that the benchmarks are\n        # compatible with versions of astropy that did not have this functionality.\n        from astropy.stats import SigmaClip\n    \n        size = (4, 2048, 2048)\n    \n        with NumpyRNGContext(12345):\n            self.data = np.random.normal(size=size)\n    \n            # add outliers\n            nbad = 100000\n            zbad = np.random.randint(low=0, high=size[0] - 1, size=nbad)\n            ybad = np.random.randint(low=0, high=size[1] - 1, size=nbad)\n            xbad = np.random.randint(low=0, high=size[2] - 1, size=nbad)\n            self.data[zbad, ybad, xbad] = (\n                np.random.choice([-1, 1], size=nbad) *\n                (10 + np.random.rand(nbad)))\n    \n            # The defaults use median as the cenfunc and standard\n            # deviation as the stdfunc.  The default iters is 5.\n            self.sigclip = SigmaClip(sigma=3)",
        "min_run_count": 2,
        "name": "stats.sigma_clipping.SigmaClipBenchmarks.time_3d_array_axis",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4ac8702969468e0e54d31ae0b462d645e1b8af9b5a394d408a5de745bf2721fd",
        "warmup_time": -1
    },
    "stats.sigma_clipping.SigmaClipBenchmarks.time_3d_array_axis2": {
        "code": "class SigmaClipBenchmarks:\n    def time_3d_array_axis2(self):\n        self.sigclip(self.data, axis=(0, 1))\n\n    def setup(self):\n    \n        # Avoid top-level module import to make sure that the benchmarks are\n        # compatible with versions of astropy that did not have this functionality.\n        from astropy.stats import SigmaClip\n    \n        size = (4, 2048, 2048)\n    \n        with NumpyRNGContext(12345):\n            self.data = np.random.normal(size=size)\n    \n            # add outliers\n            nbad = 100000\n            zbad = np.random.randint(low=0, high=size[0] - 1, size=nbad)\n            ybad = np.random.randint(low=0, high=size[1] - 1, size=nbad)\n            xbad = np.random.randint(low=0, high=size[2] - 1, size=nbad)\n            self.data[zbad, ybad, xbad] = (\n                np.random.choice([-1, 1], size=nbad) *\n                (10 + np.random.rand(nbad)))\n    \n            # The defaults use median as the cenfunc and standard\n            # deviation as the stdfunc.  The default iters is 5.\n            self.sigclip = SigmaClip(sigma=3)",
        "min_run_count": 2,
        "name": "stats.sigma_clipping.SigmaClipBenchmarks.time_3d_array_axis2",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ae3c0a9acb5075c9b0b2ea1285b46bb6d3e24ffbbe6b052c20ac63db5cdd6b65",
        "warmup_time": -1
    },
    "table.TimeMaskedColumn.time_masked_column_init": {
        "code": "class TimeMaskedColumn:\n    def time_masked_column_init(self):\n        MaskedColumn(self.dat)\n\n    def setup(self):\n        self.dat = np.arange(1e7)",
        "min_run_count": 2,
        "name": "table.TimeMaskedColumn.time_masked_column_init",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "19a45612e8367fc103c72996f1b4a413c4557962a409519e191bcfe6d125ce47",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_add_column": {
        "code": "class TimeTable:\n    def time_add_column(self):\n        self.table['e'] = self.extra_column\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_add_column",
        "number": 1,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 1,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b2c0ad0af05e6ff645357e4e21fbb3c31b647579f850c111c9494b69fecab587",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_add_row": {
        "code": "class TimeTable:\n    def time_add_row(self):\n        self.table.add_row(self.extra_row)\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_add_row",
        "number": 1,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 1,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c3da92e8384276af12dd0b284b378baea2170c58c83b6d61874804cd715d6a5f",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_aggregate": {
        "code": "class TimeTable:\n    def time_aggregate(self):\n        # Test aggregate with a function that supports reduceat\n        self.table_grouped.groups.aggregate(np.sum)\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_aggregate",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d87a6eadd3a4c94d95d33449d19c6c00474eeb1ada4b13633a28ec4e47eb57f6",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_aggregate_noreduceat": {
        "code": "class TimeTable:\n    def time_aggregate_noreduceat(self):\n        # Test aggregate with a function that doesn't support reduceat\n        self.table_grouped.groups.aggregate(lambda x: np.sum(x))\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_aggregate_noreduceat",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6607870ad7344f17d4ccea4ca0a86ce464eeccd21fe98d970ff2c699f03c7e17",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_column_get": {
        "code": "class TimeTable:\n    def time_column_get(self):\n        self.table['c']\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_column_get",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f863a90229743a65604d98100febf2400d345032ae27cbd7f0450db596a88956",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_column_make_bool_mask": {
        "code": "class TimeTable:\n    def time_column_make_bool_mask(self):\n        self.table['a'] > 0.6\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_column_make_bool_mask",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6dfae7f99d875b90ce8bb45b2232e8c9448734810edacf42fcafd45e522d1ff0",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_column_set": {
        "code": "class TimeTable:\n    def time_column_set(self):\n        self.table['a'] = 0.\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_column_set",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3b94497b8947080e3a7ad68c0d27b547fda203e3a82a6f9aef412c5b38553ce2",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_column_set_all": {
        "code": "class TimeTable:\n    def time_column_set_all(self):\n        self.table['b'][:] = True\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_column_set_all",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "42a14616589c8ebefc8d09c74be3c4b4081dc5025fc1dc68c45b04046129c898",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_column_set_row_subset": {
        "code": "class TimeTable:\n    def time_column_set_row_subset(self):\n        self.table['b'][self.bool_mask] = True\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_column_set_row_subset",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f5286a927031d2e4c72969b4294ad326f835625ffff8cab42d5a0fb0fc66d5fc",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_column_set_row_subset_int": {
        "code": "class TimeTable:\n    def time_column_set_row_subset_int(self):\n        self.table['b'][self.row_indices] = True\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_column_set_row_subset_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7a46311bfa2b1cc228c79ef31d83d80d7211b6f720c0efc76645408ecb0cc88b",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_column_slice_bool": {
        "code": "class TimeTable:\n    def time_column_slice_bool(self):\n        col_subset = self.table['a'][self.bool_mask]\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_column_slice_bool",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "606fa21ee4fae7dd015b43a97a9d3ba938acd3ba1c2b34262dd6bf6d51f33f54",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_column_slice_int": {
        "code": "class TimeTable:\n    def time_column_slice_int(self):\n        col_subset = self.table['a'][self.row_indices]\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_column_slice_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1d1818da027642ddf329e814913cf0be71476438e4a90444aa085d5f92f6fbe2",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_copy_column": {
        "code": "class TimeTable:\n    def time_copy_column(self):\n        self.table['a'].copy()\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_copy_column",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f1684c651fd087a764de4d038893b4c9610489a81f8162fa217742e1a0921bff",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_copy_table": {
        "code": "class TimeTable:\n    def time_copy_table(self):\n        self.table.copy()\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_copy_table",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9dfee0ffd435859c66c9d478df0b81fb8b7497a2a81897f10c557f39f695c328",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_group": {
        "code": "class TimeTable:\n    def time_group(self):\n        self.table.group_by('d')\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_group",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "00833c0817e383400bfaa81fbed6cd67f6bf8e38ab39dad34bf18acb12eb6240",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_hstack": {
        "code": "class TimeTable:\n    def time_hstack(self):\n        hstack([self.table, self.other_table_2])\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_hstack",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0bb53b6f70a1c0e044582584e8e4e16e12b0a6d2de3a8031520e683f725548a0",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_init_from_np_array_copy": {
        "code": "class TimeTable:\n    def time_init_from_np_array_copy(self):\n        Table(self.np_table, copy=True)\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_init_from_np_array_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4336289776445bd679565fab2aff50641d5bb4d8e1f21f2c8d37a26af69f59f8",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_init_from_np_array_no_copy": {
        "code": "class TimeTable:\n    def time_init_from_np_array_no_copy(self):\n        Table(self.np_table, copy=False)\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_init_from_np_array_no_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b13e3a0b7c95d73514fa4353bd5e2fc362b0a2133200cfbca7578616000b7c88",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_item_get_colfirst": {
        "code": "class TimeTable:\n    def time_item_get_colfirst(self):\n        self.table['b'][300]\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_item_get_colfirst",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0dd32efbfedd563aa310767ea5c4ed044e744ee7a4fbbd06b2d67f39b0646c2a",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_item_get_rowfirst": {
        "code": "class TimeTable:\n    def time_item_get_rowfirst(self):\n        self.table[300]['b']\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_item_get_rowfirst",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "09093997db41771a090f840eefd60e7d2577c519a976b9b88d799aa21d242a1b",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_iter_row": {
        "code": "class TimeTable:\n    def time_iter_row(self):\n        for row in self.table:\n            pass\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_iter_row",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5c031f2eb8938c243423fa5dabd4c66ced4063a63b583bd3f54270bc1f211fae",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_join_inner": {
        "code": "class TimeTable:\n    def time_join_inner(self):\n        join(self.table, self.other_table, keys=\"i\", join_type='inner')\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_join_inner",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0c28429345963649f5df731dce5bbd22588b0f465f5112c20ac6e8fc367697c7",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_join_outer": {
        "code": "class TimeTable:\n    def time_join_outer(self):\n        join(self.table, self.other_table, keys=\"i\", join_type='outer')\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_join_outer",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4c3bf2e6aaf0b0fa9873b63128ace026c611e846f2b72ceb1c4a7170dd790984",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_mask_column": {
        "code": "class TimeMaskedTable:\n    def time_mask_column(self):\n        self.table['a'].mask = self.bool_mask\n\nclass TimeTable:\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_mask_column",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8199306b947c7320fcf35aa5e9c87146b8bb91f9cba9d25fb9290a8ff006cee7",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_multi_column_get": {
        "code": "class TimeTable:\n    def time_multi_column_get(self):\n        self.table[('a','c')]\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_multi_column_get",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f078ef4c7d77390944802d30e7ef0381d6372c9dd211c3bb6163265eb8a8a0d9",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_read_rows": {
        "code": "class TimeTable:\n    def time_read_rows(self):\n        for row in self.table:\n            tuple(row)\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_read_rows",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b8c9879da2aac0e2ec1225c2f64e3b30c8ca22ad100b1eea118285204166f604",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_remove_column": {
        "code": "class TimeTable:\n    def time_remove_column(self):\n        self.table.remove_column('a')\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_remove_column",
        "number": 1,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 1,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ac775b1968a61183af601e5a5ebd1443c52d1e28bdb86520ac2fef19d4c38088",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_remove_row": {
        "code": "class TimeTable:\n    def time_remove_row(self):\n        self.table.remove_row(6)\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_remove_row",
        "number": 1,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 1,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a649c857c45262e8ad834755d02de13041d4fc893ecc1a30d7297f4c36541290",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_remove_rows": {
        "code": "class TimeTable:\n    def time_remove_rows(self):\n        self.table.remove_rows(self.row_indices)\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_remove_rows",
        "number": 1,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 1,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1b7c4ed8b6c2a92d93e9b2ce007c596b7c79317f1427056e26f65f9873a510ef",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_row_get": {
        "code": "class TimeTable:\n    def time_row_get(self):\n        self.table[300]\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_row_get",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "045657db9d7ef5938a36c9885c2627d0a0a8806f51a24693858d11245a8641b0",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_sort": {
        "code": "class TimeTable:\n    def time_sort(self):\n        self.table.sort('a')\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_sort",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c5563d6c2ba316f51667e1e02e88372d03a0d46ce635fcf28c99a19b8a47f364",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_table_slice_bool": {
        "code": "class TimeTable:\n    def time_table_slice_bool(self):\n        table_subset = self.table[self.bool_mask]\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_table_slice_bool",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "aa3e39b38985bb5ece815375cfeeac330868d465afe58025e987d4e6ee7b6f16",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_table_slice_int": {
        "code": "class TimeTable:\n    def time_table_slice_int(self):\n        table_subset = self.table[self.row_indices]\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_table_slice_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d371f5b0e33a94248be0e224cef150f53d07c64f2e16111a308b57b90ad93080",
        "warmup_time": -1
    },
    "table.TimeMaskedTable.time_vstack": {
        "code": "class TimeTable:\n    def time_vstack(self):\n        vstack([self.table, self.table])\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeMaskedTable.time_vstack",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "398d840ff2c40a226540b887b02f1c56020693a589a7526505fd59479cc7256b",
        "warmup_time": -1
    },
    "table.TimeTable.time_add_column": {
        "code": "class TimeTable:\n    def time_add_column(self):\n        self.table['e'] = self.extra_column\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_add_column",
        "number": 1,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 1,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b2c0ad0af05e6ff645357e4e21fbb3c31b647579f850c111c9494b69fecab587",
        "warmup_time": -1
    },
    "table.TimeTable.time_add_row": {
        "code": "class TimeTable:\n    def time_add_row(self):\n        self.table.add_row(self.extra_row)\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_add_row",
        "number": 1,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 1,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c3da92e8384276af12dd0b284b378baea2170c58c83b6d61874804cd715d6a5f",
        "warmup_time": -1
    },
    "table.TimeTable.time_aggregate": {
        "code": "class TimeTable:\n    def time_aggregate(self):\n        # Test aggregate with a function that supports reduceat\n        self.table_grouped.groups.aggregate(np.sum)\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_aggregate",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d87a6eadd3a4c94d95d33449d19c6c00474eeb1ada4b13633a28ec4e47eb57f6",
        "warmup_time": -1
    },
    "table.TimeTable.time_aggregate_noreduceat": {
        "code": "class TimeTable:\n    def time_aggregate_noreduceat(self):\n        # Test aggregate with a function that doesn't support reduceat\n        self.table_grouped.groups.aggregate(lambda x: np.sum(x))\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_aggregate_noreduceat",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6607870ad7344f17d4ccea4ca0a86ce464eeccd21fe98d970ff2c699f03c7e17",
        "warmup_time": -1
    },
    "table.TimeTable.time_column_get": {
        "code": "class TimeTable:\n    def time_column_get(self):\n        self.table['c']\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_column_get",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f863a90229743a65604d98100febf2400d345032ae27cbd7f0450db596a88956",
        "warmup_time": -1
    },
    "table.TimeTable.time_column_make_bool_mask": {
        "code": "class TimeTable:\n    def time_column_make_bool_mask(self):\n        self.table['a'] > 0.6\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_column_make_bool_mask",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6dfae7f99d875b90ce8bb45b2232e8c9448734810edacf42fcafd45e522d1ff0",
        "warmup_time": -1
    },
    "table.TimeTable.time_column_set": {
        "code": "class TimeTable:\n    def time_column_set(self):\n        self.table['a'] = 0.\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_column_set",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3b94497b8947080e3a7ad68c0d27b547fda203e3a82a6f9aef412c5b38553ce2",
        "warmup_time": -1
    },
    "table.TimeTable.time_column_set_all": {
        "code": "class TimeTable:\n    def time_column_set_all(self):\n        self.table['b'][:] = True\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_column_set_all",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "42a14616589c8ebefc8d09c74be3c4b4081dc5025fc1dc68c45b04046129c898",
        "warmup_time": -1
    },
    "table.TimeTable.time_column_set_row_subset": {
        "code": "class TimeTable:\n    def time_column_set_row_subset(self):\n        self.table['b'][self.bool_mask] = True\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_column_set_row_subset",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f5286a927031d2e4c72969b4294ad326f835625ffff8cab42d5a0fb0fc66d5fc",
        "warmup_time": -1
    },
    "table.TimeTable.time_column_set_row_subset_int": {
        "code": "class TimeTable:\n    def time_column_set_row_subset_int(self):\n        self.table['b'][self.row_indices] = True\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_column_set_row_subset_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7a46311bfa2b1cc228c79ef31d83d80d7211b6f720c0efc76645408ecb0cc88b",
        "warmup_time": -1
    },
    "table.TimeTable.time_column_slice_bool": {
        "code": "class TimeTable:\n    def time_column_slice_bool(self):\n        col_subset = self.table['a'][self.bool_mask]\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_column_slice_bool",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "606fa21ee4fae7dd015b43a97a9d3ba938acd3ba1c2b34262dd6bf6d51f33f54",
        "warmup_time": -1
    },
    "table.TimeTable.time_column_slice_int": {
        "code": "class TimeTable:\n    def time_column_slice_int(self):\n        col_subset = self.table['a'][self.row_indices]\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_column_slice_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1d1818da027642ddf329e814913cf0be71476438e4a90444aa085d5f92f6fbe2",
        "warmup_time": -1
    },
    "table.TimeTable.time_copy_column": {
        "code": "class TimeTable:\n    def time_copy_column(self):\n        self.table['a'].copy()\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_copy_column",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f1684c651fd087a764de4d038893b4c9610489a81f8162fa217742e1a0921bff",
        "warmup_time": -1
    },
    "table.TimeTable.time_copy_table": {
        "code": "class TimeTable:\n    def time_copy_table(self):\n        self.table.copy()\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_copy_table",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9dfee0ffd435859c66c9d478df0b81fb8b7497a2a81897f10c557f39f695c328",
        "warmup_time": -1
    },
    "table.TimeTable.time_group": {
        "code": "class TimeTable:\n    def time_group(self):\n        self.table.group_by('d')\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_group",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "00833c0817e383400bfaa81fbed6cd67f6bf8e38ab39dad34bf18acb12eb6240",
        "warmup_time": -1
    },
    "table.TimeTable.time_hstack": {
        "code": "class TimeTable:\n    def time_hstack(self):\n        hstack([self.table, self.other_table_2])\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_hstack",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0bb53b6f70a1c0e044582584e8e4e16e12b0a6d2de3a8031520e683f725548a0",
        "warmup_time": -1
    },
    "table.TimeTable.time_init_from_np_array_copy": {
        "code": "class TimeTable:\n    def time_init_from_np_array_copy(self):\n        Table(self.np_table, copy=True)\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_init_from_np_array_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4336289776445bd679565fab2aff50641d5bb4d8e1f21f2c8d37a26af69f59f8",
        "warmup_time": -1
    },
    "table.TimeTable.time_init_from_np_array_no_copy": {
        "code": "class TimeTable:\n    def time_init_from_np_array_no_copy(self):\n        Table(self.np_table, copy=False)\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_init_from_np_array_no_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b13e3a0b7c95d73514fa4353bd5e2fc362b0a2133200cfbca7578616000b7c88",
        "warmup_time": -1
    },
    "table.TimeTable.time_item_get_colfirst": {
        "code": "class TimeTable:\n    def time_item_get_colfirst(self):\n        self.table['b'][300]\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_item_get_colfirst",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0dd32efbfedd563aa310767ea5c4ed044e744ee7a4fbbd06b2d67f39b0646c2a",
        "warmup_time": -1
    },
    "table.TimeTable.time_item_get_rowfirst": {
        "code": "class TimeTable:\n    def time_item_get_rowfirst(self):\n        self.table[300]['b']\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_item_get_rowfirst",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "09093997db41771a090f840eefd60e7d2577c519a976b9b88d799aa21d242a1b",
        "warmup_time": -1
    },
    "table.TimeTable.time_iter_row": {
        "code": "class TimeTable:\n    def time_iter_row(self):\n        for row in self.table:\n            pass\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_iter_row",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5c031f2eb8938c243423fa5dabd4c66ced4063a63b583bd3f54270bc1f211fae",
        "warmup_time": -1
    },
    "table.TimeTable.time_join_inner": {
        "code": "class TimeTable:\n    def time_join_inner(self):\n        join(self.table, self.other_table, keys=\"i\", join_type='inner')\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_join_inner",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0c28429345963649f5df731dce5bbd22588b0f465f5112c20ac6e8fc367697c7",
        "warmup_time": -1
    },
    "table.TimeTable.time_join_outer": {
        "code": "class TimeTable:\n    def time_join_outer(self):\n        join(self.table, self.other_table, keys=\"i\", join_type='outer')\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_join_outer",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4c3bf2e6aaf0b0fa9873b63128ace026c611e846f2b72ceb1c4a7170dd790984",
        "warmup_time": -1
    },
    "table.TimeTable.time_multi_column_get": {
        "code": "class TimeTable:\n    def time_multi_column_get(self):\n        self.table[('a','c')]\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_multi_column_get",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f078ef4c7d77390944802d30e7ef0381d6372c9dd211c3bb6163265eb8a8a0d9",
        "warmup_time": -1
    },
    "table.TimeTable.time_read_rows": {
        "code": "class TimeTable:\n    def time_read_rows(self):\n        for row in self.table:\n            tuple(row)\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_read_rows",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b8c9879da2aac0e2ec1225c2f64e3b30c8ca22ad100b1eea118285204166f604",
        "warmup_time": -1
    },
    "table.TimeTable.time_remove_column": {
        "code": "class TimeTable:\n    def time_remove_column(self):\n        self.table.remove_column('a')\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_remove_column",
        "number": 1,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 1,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ac775b1968a61183af601e5a5ebd1443c52d1e28bdb86520ac2fef19d4c38088",
        "warmup_time": -1
    },
    "table.TimeTable.time_remove_row": {
        "code": "class TimeTable:\n    def time_remove_row(self):\n        self.table.remove_row(6)\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_remove_row",
        "number": 1,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 1,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a649c857c45262e8ad834755d02de13041d4fc893ecc1a30d7297f4c36541290",
        "warmup_time": -1
    },
    "table.TimeTable.time_remove_rows": {
        "code": "class TimeTable:\n    def time_remove_rows(self):\n        self.table.remove_rows(self.row_indices)\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_remove_rows",
        "number": 1,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 1,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1b7c4ed8b6c2a92d93e9b2ce007c596b7c79317f1427056e26f65f9873a510ef",
        "warmup_time": -1
    },
    "table.TimeTable.time_row_get": {
        "code": "class TimeTable:\n    def time_row_get(self):\n        self.table[300]\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_row_get",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "045657db9d7ef5938a36c9885c2627d0a0a8806f51a24693858d11245a8641b0",
        "warmup_time": -1
    },
    "table.TimeTable.time_sort": {
        "code": "class TimeTable:\n    def time_sort(self):\n        self.table.sort('a')\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_sort",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c5563d6c2ba316f51667e1e02e88372d03a0d46ce635fcf28c99a19b8a47f364",
        "warmup_time": -1
    },
    "table.TimeTable.time_table_slice_bool": {
        "code": "class TimeTable:\n    def time_table_slice_bool(self):\n        table_subset = self.table[self.bool_mask]\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_table_slice_bool",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "aa3e39b38985bb5ece815375cfeeac330868d465afe58025e987d4e6ee7b6f16",
        "warmup_time": -1
    },
    "table.TimeTable.time_table_slice_int": {
        "code": "class TimeTable:\n    def time_table_slice_int(self):\n        table_subset = self.table[self.row_indices]\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_table_slice_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d371f5b0e33a94248be0e224cef150f53d07c64f2e16111a308b57b90ad93080",
        "warmup_time": -1
    },
    "table.TimeTable.time_vstack": {
        "code": "class TimeTable:\n    def time_vstack(self):\n        vstack([self.table, self.table])\n\n    def setup(self):\n    \n        # Initialize table\n        self.table = Table(masked=self.masked)\n    \n        # Create column with mixed types\n        np.random.seed(12345)\n        self.table['i'] = np.arange(1000)\n        self.table['a'] = np.random.random(1000)  # float\n        self.table['b'] = np.random.random(1000) > 0.5  # bool\n        self.table['c'] = np.random.random((1000,10))  # 2d column\n        self.table['d'] = np.random.choice(np.array(list(string.ascii_letters)),1000)\n    \n        self.np_table = np.array(self.table)\n    \n        self.extra_row = {'a':1.2, 'b':True, 'c':np.repeat(1, 10), 'd': 'Z'}\n    \n        self.extra_column = np.random.randint(0, 100, 1000)\n    \n        self.row_indices = np.where(self.table['a'] > 0.9)[0]\n    \n        self.table_grouped = self.table.group_by('d')\n    \n        # Another table for testing joining\n        self.other_table = Table(masked=self.masked)\n        self.other_table['i'] = np.arange(1,1000,3)\n        self.other_table['f'] = np.random.random()\n        self.other_table.sort('f')\n    \n        # Another table for testing hstack\n        self.other_table_2 = Table(masked=self.masked)\n        self.other_table_2['g'] = np.random.random(1000)\n        self.other_table_2['h'] = np.random.random((1000, 10))\n    \n        self.bool_mask = self.table['a'] > 0.6",
        "min_run_count": 2,
        "name": "table.TimeTable.time_vstack",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "398d840ff2c40a226540b887b02f1c56020693a589a7526505fd59479cc7256b",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArray.time_quantity_np_sqrt": {
        "code": "class TimeQuantityOpSmallArray:\n    def time_quantity_np_sqrt(self):\n        np.sqrt(self.data)\n\nclass TimeQuantityOpLargeArray:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.out = data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArray.time_quantity_np_sqrt",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "551dfacb666b0837fe33d0f2376517392bbe64eb75e9a0281110ab5c5347adc6",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArray.time_quantity_np_sqrt_out": {
        "code": "class TimeQuantityOpSmallArray:\n    def time_quantity_np_sqrt_out(self):\n        np.sqrt(self.data, out=self.out)\n\nclass TimeQuantityOpLargeArray:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.out = data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArray.time_quantity_np_sqrt_out",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "41be966ca65c376e81d9b3a93ff8aa5d0045d99d17bf8e962bb875470ed481f8",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArray.time_quantity_np_square": {
        "code": "class TimeQuantityOpSmallArray:\n    def time_quantity_np_square(self):\n        np.power(self.data, 2)\n\nclass TimeQuantityOpLargeArray:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.out = data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArray.time_quantity_np_square",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "720e4eaaee8fb2facc7f1012064384e29c68237343d5d603f415318b6ff2d8f3",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArray.time_quantity_np_square_out": {
        "code": "class TimeQuantityOpSmallArray:\n    def time_quantity_np_square_out(self):\n        np.power(self.data, 2, out=self.out)\n\nclass TimeQuantityOpLargeArray:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.out = data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArray.time_quantity_np_square_out",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7765895d6298d4a8ef8c3cc472af5e04c56460dc4bef6e6b0fd10d30bf450998",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArray.time_quantity_sqrt": {
        "code": "class TimeQuantityOpSmallArray:\n    def time_quantity_sqrt(self):\n        self.data ** 0.5\n\nclass TimeQuantityOpLargeArray:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.out = data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArray.time_quantity_sqrt",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4ea643745de7ed830917db055ec4824b4a23cafdd0247730e6cc5a6796b63325",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArray.time_quantity_square": {
        "code": "class TimeQuantityOpSmallArray:\n    def time_quantity_square(self):\n        self.data ** 2\n\nclass TimeQuantityOpLargeArray:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.out = data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArray.time_quantity_square",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4eaef1127932b45da406d52f106a92865b973d3a882af5b3bdf6a6caeae0e492",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_add": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_add(self):\n        # Same as operator.add\n        self.data + self.data2\n\nclass TimeQuantityOpLargeArrayDiffUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_add",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c385cebfe41635e363e477dcb78af200f30065955a278796767c4a451caae1c9",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_equal": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_equal(self):\n        # Same as operator.eq\n        self.data == self.data2\n\nclass TimeQuantityOpLargeArrayDiffUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b9eb2d23ce1438d33e7a6c9427268e1510d0326bd38ecad2c556256a974781cc",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_mul": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_mul(self):\n        # Same as operator.mul\n        self.data * self.data2\n\nclass TimeQuantityOpLargeArrayDiffUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_mul",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7751a2973c3e178742fab8fb48b2d37deeb9f1d30f9fa42709bfe7a121fba06d",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_np_add": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_add(self):\n        np.add(self.data, self.data2)\n\nclass TimeQuantityOpLargeArrayDiffUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_np_add",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7de933e8733313f06bdc7db668d354ee1049132e444ed2e2318f44ada5ff32b5",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_np_equal": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_equal(self):\n        np.equal(self.data, self.data2)\n\nclass TimeQuantityOpLargeArrayDiffUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_np_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "248558ce92d50fa897e52b0331a11dbbb8a59515efd6cef4bff676ed001169f0",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_np_multiply": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_multiply(self):\n        np.multiply(self.data, self.data2)\n\nclass TimeQuantityOpLargeArrayDiffUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_np_multiply",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "69dbd5da2de39350eace04fe175f776f41d79f31f652962ceb3508da490ba500",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_np_subtract": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_subtract(self):\n        np.subtract(self.data, self.data2)\n\nclass TimeQuantityOpLargeArrayDiffUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_np_subtract",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d63b43847ef0711c37d11de7f00a27d703c6c2199356465aa7748260f4ce7e03",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_np_truediv": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_truediv(self):\n        np.true_divide(self.data, self.data2)\n\nclass TimeQuantityOpLargeArrayDiffUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_np_truediv",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "419f603b0bb9da0db98d7847cfc33e64009f7ffe8affb88d9fe22a3101efb9e0",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_sub": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_sub(self):\n        # Same as operator.sub\n        self.data - self.data2\n\nclass TimeQuantityOpLargeArrayDiffUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_sub",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2291156c51760e7bfde8a80525db9c92a1569795e75854b72cfe9da8cf9a8540",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_truediv": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_truediv(self):\n        # Since benchmark is PY3 only, this is always true divide.\n        # Same as operator.truediv\n        self.data / self.data2\n\nclass TimeQuantityOpLargeArrayDiffUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArrayDiffUnit.time_quantity_truediv",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b97569c5e7e9ea3949d6a792e5a072098dd90e8bafe901e310c975220144754c",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArraySameUnit.time_quantity_add": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_add(self):\n        # Same as operator.add\n        self.data + self.data2\n\nclass TimeQuantityOpLargeArraySameUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArraySameUnit.time_quantity_add",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1340fecc25ccfe6db8ba2d16b907cdecc04639a5eb0f453948f42583aa2d1020",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArraySameUnit.time_quantity_equal": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_equal(self):\n        # Same as operator.eq\n        self.data == self.data2\n\nclass TimeQuantityOpLargeArraySameUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArraySameUnit.time_quantity_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "64fc765c126a1ea33be0fe1bb49cc0d5684cd0504a6ea698db4c0a289f96aa6d",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArraySameUnit.time_quantity_mul": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_mul(self):\n        # Same as operator.mul\n        self.data * self.data2\n\nclass TimeQuantityOpLargeArraySameUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArraySameUnit.time_quantity_mul",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "902a17a4038cf248441bd8aa9d4d8e17f063cb35ca8daef05bb2fb5599bd63a9",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArraySameUnit.time_quantity_np_add": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_add(self):\n        np.add(self.data, self.data2)\n\nclass TimeQuantityOpLargeArraySameUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArraySameUnit.time_quantity_np_add",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "654dee8983d688239420d427ddc1657b002ccbf3bf7faf2fe803a024244e44fb",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArraySameUnit.time_quantity_np_equal": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_equal(self):\n        np.equal(self.data, self.data2)\n\nclass TimeQuantityOpLargeArraySameUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArraySameUnit.time_quantity_np_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ea9059e90756adf2c76d445733343ec9700bb5c2a36b6d0d3500881618525ee0",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArraySameUnit.time_quantity_np_multiply": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_multiply(self):\n        np.multiply(self.data, self.data2)\n\nclass TimeQuantityOpLargeArraySameUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArraySameUnit.time_quantity_np_multiply",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "709731432d1b10fb1278092a086b905109373969c618296298c0758436bf2799",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArraySameUnit.time_quantity_np_subtract": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_subtract(self):\n        np.subtract(self.data, self.data2)\n\nclass TimeQuantityOpLargeArraySameUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArraySameUnit.time_quantity_np_subtract",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d457e6547ebaf3987a3c4a2573c095cd7fa45dad108fced3facac3678425c28c",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArraySameUnit.time_quantity_np_truediv": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_truediv(self):\n        np.true_divide(self.data, self.data2)\n\nclass TimeQuantityOpLargeArraySameUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArraySameUnit.time_quantity_np_truediv",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e5389c843adadc1c3898b7f5a3623ee6b16ac3eabbf7e36e26ad332af83ad19c",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArraySameUnit.time_quantity_sub": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_sub(self):\n        # Same as operator.sub\n        self.data - self.data2\n\nclass TimeQuantityOpLargeArraySameUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArraySameUnit.time_quantity_sub",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f633c739ee865adca9fead5896feec7037bcd079ec31c14132cd331f5475b56f",
        "warmup_time": -1
    },
    "units.TimeQuantityOpLargeArraySameUnit.time_quantity_truediv": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_truediv(self):\n        # Since benchmark is PY3 only, this is always true divide.\n        # Same as operator.truediv\n        self.data / self.data2\n\nclass TimeQuantityOpLargeArraySameUnit:\n    def setup(self):\n        data = np.arange(1e6) + 1\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpLargeArraySameUnit.time_quantity_truediv",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "87e7418488429f293a0fe0b0dadb7acf20a52dd3591ad92e9dfcdeeb4e908374",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArray.time_quantity_np_sqrt": {
        "code": "class TimeQuantityOpSmallArray:\n    def time_quantity_np_sqrt(self):\n        np.sqrt(self.data)\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.out = data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArray.time_quantity_np_sqrt",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f7ae52f73925b5abd9dc83d8f3d465353ee1b956911c3d0011148e4d43b19fb1",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArray.time_quantity_np_sqrt_out": {
        "code": "class TimeQuantityOpSmallArray:\n    def time_quantity_np_sqrt_out(self):\n        np.sqrt(self.data, out=self.out)\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.out = data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArray.time_quantity_np_sqrt_out",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2934bd0bcf29004357eae0a4cb2ef6f3d21df9fc55f7b6a169cfdd33f3702279",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArray.time_quantity_np_square": {
        "code": "class TimeQuantityOpSmallArray:\n    def time_quantity_np_square(self):\n        np.power(self.data, 2)\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.out = data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArray.time_quantity_np_square",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4e68f505b36255eb9d1614733bde960880bc1d1a8ca52245b754c61a01d1b849",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArray.time_quantity_np_square_out": {
        "code": "class TimeQuantityOpSmallArray:\n    def time_quantity_np_square_out(self):\n        np.power(self.data, 2, out=self.out)\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.out = data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArray.time_quantity_np_square_out",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "048aa7bf6d2097b9ccf070755ba1cede783dfb722a6e35cc85cb8f3713db0608",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArray.time_quantity_sqrt": {
        "code": "class TimeQuantityOpSmallArray:\n    def time_quantity_sqrt(self):\n        self.data ** 0.5\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.out = data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArray.time_quantity_sqrt",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f00664003bfaf1d50000121c8f6f3b57a53dff588ca56bb85b4c03f7008ea8ea",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArray.time_quantity_square": {
        "code": "class TimeQuantityOpSmallArray:\n    def time_quantity_square(self):\n        self.data ** 2\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.out = data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArray.time_quantity_square",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ca9cc7c5e8745dcbcf9c9eb7ca1bd446e4ac66846e6c7a0ad131b396a6cc9d12",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_add": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_add(self):\n        # Same as operator.add\n        self.data + self.data2\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_add",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0d81504f4f1b242de1f59e2ab063da3e645daaf2416a29a3543ae1d67b0c16f1",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_equal": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_equal(self):\n        # Same as operator.eq\n        self.data == self.data2\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0bd368751da8a7cf699cc3b5506d6a1a9a916728fe2d60dc00d0c8f38362314f",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_mul": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_mul(self):\n        # Same as operator.mul\n        self.data * self.data2\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_mul",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0fdebeba31662edc0a7953ad173a86749daf325bf79cc4d96db3dda45531001b",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_np_add": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_add(self):\n        np.add(self.data, self.data2)\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_np_add",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "10bc2cc18d02ec2db40df7a5e95743cf5d8ab46da4ce7070b8f447980c8fc389",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_np_equal": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_equal(self):\n        np.equal(self.data, self.data2)\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_np_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "35de01ee895de6e288d8be9f9a8129bcf3a3c807aca16819286cbc7c58b7464e",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_np_multiply": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_multiply(self):\n        np.multiply(self.data, self.data2)\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_np_multiply",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "68ce50141b0faf216b28687045e3b5b1f3e90c8d30f3a701c5fb1b3d5f4423c1",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_np_subtract": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_subtract(self):\n        np.subtract(self.data, self.data2)\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_np_subtract",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5976eb02a4c22931cfe8a53e0662ea551e9d8bcad8dc3ae559ddc92ea08fff6a",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_np_truediv": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_truediv(self):\n        np.true_divide(self.data, self.data2)\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_np_truediv",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ac6ce9ff628a808cb007223a9d72d57b84581b016533279483cbd2f27af6f67a",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_sub": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_sub(self):\n        # Same as operator.sub\n        self.data - self.data2\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_sub",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7addf2162752672919abc9e95803a571972a1d0de313e65e92cbe979d2be8069",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_truediv": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_truediv(self):\n        # Since benchmark is PY3 only, this is always true divide.\n        # Same as operator.truediv\n        self.data / self.data2\n\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n    \n        # A different but dimensionally compatible unit\n        self.data2 = 0.001 * data * u.kg",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArrayDiffUnit.time_quantity_truediv",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "675ddc8c55b1273b5210b8127dea06c9ee5d42c4a3292b5e00d85cc89b7740e7",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArraySameUnit.time_quantity_add": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_add(self):\n        # Same as operator.add\n        self.data + self.data2\n\nclass TimeQuantityOpSmallArraySameUnit:\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArraySameUnit.time_quantity_add",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "db5eac4d553d53a2c73a2a5b0c9664f7aa328de33759deab21ebc45ea384559c",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArraySameUnit.time_quantity_equal": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_equal(self):\n        # Same as operator.eq\n        self.data == self.data2\n\nclass TimeQuantityOpSmallArraySameUnit:\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArraySameUnit.time_quantity_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3653421d580026ffa717b37ad30bf711b120a1e147621157f8fa94c0ce1b6fd1",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArraySameUnit.time_quantity_mul": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_mul(self):\n        # Same as operator.mul\n        self.data * self.data2\n\nclass TimeQuantityOpSmallArraySameUnit:\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArraySameUnit.time_quantity_mul",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c0d41b641af56a1e819ea80933ee0b7492e484c0051492cb767aca7a656682f4",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArraySameUnit.time_quantity_np_add": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_add(self):\n        np.add(self.data, self.data2)\n\nclass TimeQuantityOpSmallArraySameUnit:\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArraySameUnit.time_quantity_np_add",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9e21e621002197a56ec29cbef1528fe5612737320a8a72c6b51b330916e08d16",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArraySameUnit.time_quantity_np_equal": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_equal(self):\n        np.equal(self.data, self.data2)\n\nclass TimeQuantityOpSmallArraySameUnit:\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArraySameUnit.time_quantity_np_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e14f490308a0eabaf254e1ca5fe97908999dd7ed77a379d7d07cb2bd98d239a4",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArraySameUnit.time_quantity_np_multiply": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_multiply(self):\n        np.multiply(self.data, self.data2)\n\nclass TimeQuantityOpSmallArraySameUnit:\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArraySameUnit.time_quantity_np_multiply",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7685f6b49aec13a41bbca6518c60d29f3f7db3249c88e00ad42d0c068a9c5a32",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArraySameUnit.time_quantity_np_subtract": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_subtract(self):\n        np.subtract(self.data, self.data2)\n\nclass TimeQuantityOpSmallArraySameUnit:\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArraySameUnit.time_quantity_np_subtract",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6273a7aacc091f814d9e9fc5e3a43ea94842f71e136211e32930027169486dec",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArraySameUnit.time_quantity_np_truediv": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_np_truediv(self):\n        np.true_divide(self.data, self.data2)\n\nclass TimeQuantityOpSmallArraySameUnit:\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArraySameUnit.time_quantity_np_truediv",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b8c3047cf2e12e2cd376a25a8c4870bc9e189c56bdd1c732f3c59566d1c3f778",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArraySameUnit.time_quantity_sub": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_sub(self):\n        # Same as operator.sub\n        self.data - self.data2\n\nclass TimeQuantityOpSmallArraySameUnit:\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArraySameUnit.time_quantity_sub",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "79b8850bedab52cc9feab4702429e899eb950d47c2c72f1e397f869f03bed5d0",
        "warmup_time": -1
    },
    "units.TimeQuantityOpSmallArraySameUnit.time_quantity_truediv": {
        "code": "class TimeQuantityOpSmallArrayDiffUnit:\n    def time_quantity_truediv(self):\n        # Since benchmark is PY3 only, this is always true divide.\n        # Same as operator.truediv\n        self.data / self.data2\n\nclass TimeQuantityOpSmallArraySameUnit:\n    def setup(self):\n        data = np.array([1., 2., 3.])\n        self.data = data * u.g\n        self.data2 = self.data.copy()",
        "min_run_count": 2,
        "name": "units.TimeQuantityOpSmallArraySameUnit.time_quantity_truediv",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "90ce3d4ad893becbe16681c6534a2c345f647363c0440f12a8666eea7bff3023",
        "warmup_time": -1
    },
    "units.mem_unit": {
        "code": "def mem_unit():\n    return u.erg",
        "name": "units.mem_unit",
        "param_names": [],
        "params": [],
        "timeout": 60.0,
        "type": "memory",
        "unit": "bytes",
        "version": "3a897822d63f1fc4ebc8b6f605d236642698676d05ca2a2f415a55cee964d2b8"
    },
    "units.time_compose_complex": {
        "code": "def time_compose_complex():\n    # Composing a complex unit can be very inefficient\n    (u.kg / u.s ** 3 * u.au ** 2.5 / u.yr ** 0.5 / u.sr ** 2).compose()",
        "min_run_count": 2,
        "name": "units.time_compose_complex",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "52ea1360a73607e97f50ceef1e3f3e3e848ad83b0b5362a19e4aa3fb3dceca04",
        "warmup_time": -1
    },
    "units.time_compose_to_bases": {
        "code": "def time_compose_to_bases():\n    x = copy.copy(u.Ry)\n    x.cgs",
        "min_run_count": 2,
        "name": "units.time_compose_to_bases",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "efa81d39b97d426d435dbe325a091874c13cd833db4885fd5e9e1ec35b231e35",
        "warmup_time": -1
    },
    "units.time_quantity_array_conversion": {
        "code": "def time_quantity_array_conversion():\n    (a * u.m / u.s).to(u.km / u.hour)",
        "min_run_count": 2,
        "name": "units.time_quantity_array_conversion",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "453720a338fd6209fec908aeca1d32fd167c1889d2cf194fb9cc93798ba4f918",
        "warmup_time": -1
    },
    "units.time_quantity_creation": {
        "code": "def time_quantity_creation():\n    u.Quantity(a, u.m)",
        "min_run_count": 2,
        "name": "units.time_quantity_creation",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "57da636a893f32b10c058bef66b505734774f0254e5ec31d8102670ea3749ba1",
        "warmup_time": -1
    },
    "units.time_quantity_creation_nocopy": {
        "code": "def time_quantity_creation_nocopy():\n    u.Quantity(a, u.m, copy=False)",
        "min_run_count": 2,
        "name": "units.time_quantity_creation_nocopy",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1b32a659e9bbcfc671c6339f519316d7f3586bf52e9adfff2524d9ed7c3efe92",
        "warmup_time": -1
    },
    "units.time_quantity_init_array": {
        "code": "def time_quantity_init_array():\n    a * u.m / u.s",
        "min_run_count": 2,
        "name": "units.time_quantity_init_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "957f8f9cf4974efcf01e8818e1f02c7f19f8d19c00d1a379e4038026c1a12d44",
        "warmup_time": -1
    },
    "units.time_quantity_init_scalar": {
        "code": "def time_quantity_init_scalar():\n    3. * u.m / u.s",
        "min_run_count": 2,
        "name": "units.time_quantity_init_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1f7132881f0240f773268d410a62cf9914eff40bd73ad1fd726217c1fb31dc3e",
        "warmup_time": -1
    },
    "units.time_quantity_init_small_array": {
        "code": "def time_quantity_init_small_array():\n    \"\"\"\n    https://github.com/astropy/astropy/issues/7546 reported high overhead\n    for small array.\n    \"\"\"\n    b2 * u.m / u.s",
        "min_run_count": 2,
        "name": "units.time_quantity_init_small_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e442253d950daa145a563a26e080a23c9196e7b4ed1653d63f04adbbbfc4886a",
        "warmup_time": -1
    },
    "units.time_quantity_init_small_list": {
        "code": "def time_quantity_init_small_list():\n    \"\"\"\n    https://github.com/astropy/astropy/issues/7546 reported high overhead\n    for small list.\n    \"\"\"\n    b1 * u.m / u.s",
        "min_run_count": 2,
        "name": "units.time_quantity_init_small_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "251802d8b8d567ff4a2283a83f7a4c7baa31159203b7efd9ad77ccfd4f150767",
        "warmup_time": -1
    },
    "units.time_quantity_scalar_conversion": {
        "code": "def time_quantity_scalar_conversion():\n    (3. * u.m / u.s).to(u.km / u.hour)",
        "min_run_count": 2,
        "name": "units.time_quantity_scalar_conversion",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0bc23b508de4b7bbd0fe029aa99741c170acb5975e60e82d95df92c5c4ae0a94",
        "warmup_time": -1
    },
    "units.time_quantity_times_quantity": {
        "code": "def time_quantity_times_quantity():\n    q1 * q0",
        "min_run_count": 2,
        "name": "units.time_quantity_times_quantity",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "33b450d74c52eb7359c2d056eff45d449f4158a1a0c433bd7a4ab035544b3344",
        "warmup_time": -1
    },
    "units.time_quantity_times_unit": {
        "code": "def time_quantity_times_unit():\n    q1 * u.m",
        "min_run_count": 2,
        "name": "units.time_quantity_times_unit",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "18101a547d2f59990d20d563f3734a998e00684852452c7778f2425883693063",
        "warmup_time": -1
    },
    "units.time_quantity_ufunc_sin": {
        "code": "def time_quantity_ufunc_sin():\n    np.sin(q2)",
        "min_run_count": 2,
        "name": "units.time_quantity_ufunc_sin",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6782df2b41ecd8117cefb86c1097ead62fbc89a35d3b19a64b90f3036ea24e15",
        "warmup_time": -1
    },
    "units.time_quantity_view": {
        "code": "def time_quantity_view():\n    q1.view(u.Quantity)",
        "min_run_count": 2,
        "name": "units.time_quantity_view",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "26ddf3059fc7b8c7c4410ec065066c9f1d29eee90d7da6033ef7fd194dc03c0e",
        "warmup_time": -1
    },
    "units.time_simple_unit_parse": {
        "code": "def time_simple_unit_parse():\n    u.Unit('1 d')",
        "min_run_count": 2,
        "name": "units.time_simple_unit_parse",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "18937913b36f94725f1c97a07a4783897c64f748e4ca3438d8a366ec405ff794",
        "warmup_time": -1
    },
    "units.time_unit_compose": {
        "code": "def time_unit_compose():\n    u.Ry.compose()",
        "min_run_count": 2,
        "name": "units.time_unit_compose",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c411870dd43a755992fbca4dc50586233a3eb250670f7ecd6e3861bdc3713d04",
        "warmup_time": -1
    },
    "units.time_unit_parse": {
        "code": "def time_unit_parse():\n    u.Unit('1e-07 kg m2 / s2')",
        "min_run_count": 2,
        "name": "units.time_unit_parse",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "197b3554fa4d3e39fa3aae6a308abe51ad542092cad5f0868867bc8fa021781f",
        "warmup_time": -1
    },
    "units.time_unit_to": {
        "code": "def time_unit_to():\n    u.m.to(u.pc)",
        "min_run_count": 2,
        "name": "units.time_unit_to",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6da60807eb0884de058d60357ad655c1d2db3bae2d58d75ddbc21222a2210610",
        "warmup_time": -1
    },
    "units.time_very_simple_unit_parse": {
        "code": "def time_very_simple_unit_parse():\n    u.Unit('d')",
        "min_run_count": 2,
        "name": "units.time_very_simple_unit_parse",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "21b39993087943b0334e5ed6ac90834c28d709457c414dde5c53f37387b41fdf",
        "warmup_time": -1
    },
    "version": 2,
    "visualization.wcsaxes.time_basic_plot": {
        "code": "def time_basic_plot():\n\n    fig = Figure()\n    canvas = FigureCanvas(fig)\n\n    ax = WCSAxes(fig, [0.15, 0.15, 0.7, 0.7], wcs=MSX_WCS)\n    fig.add_axes(ax)\n\n    ax.set_xlim(-0.5, 148.5)\n    ax.set_ylim(-0.5, 148.5)\n\n    canvas.draw()",
        "min_run_count": 2,
        "name": "visualization.wcsaxes.time_basic_plot",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7ec5695860cae34277828c35c0b049fd50bffd8ae413a6e3db7d7f934f1843db",
        "warmup_time": -1
    },
    "visualization.wcsaxes.time_basic_plot_with_grid": {
        "code": "def time_basic_plot_with_grid():\n\n    fig = Figure()\n    canvas = FigureCanvas(fig)\n\n    ax = WCSAxes(fig, [0.15, 0.15, 0.7, 0.7], wcs=MSX_WCS)\n    fig.add_axes(ax)\n\n    ax.grid(color='red', alpha=0.5, linestyle='solid')\n\n    ax.set_xlim(-0.5, 148.5)\n    ax.set_ylim(-0.5, 148.5)\n\n    canvas.draw()",
        "min_run_count": 2,
        "name": "visualization.wcsaxes.time_basic_plot_with_grid",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "27a3a0412eced0052cba10bab2b0ac3f13129808dfac0dc0ebaa1d469475412d",
        "warmup_time": -1
    },
    "visualization.wcsaxes.time_basic_plot_with_grid_and_overlay": {
        "code": "def time_basic_plot_with_grid_and_overlay():\n\n    fig = Figure()\n    canvas = FigureCanvas(fig)\n\n    ax = WCSAxes(fig, [0.15, 0.15, 0.7, 0.7], wcs=MSX_WCS)\n    fig.add_axes(ax)\n\n    ax.grid(color='red', alpha=0.5, linestyle='solid')\n\n    ax.set_xlim(-0.5, 148.5)\n    ax.set_ylim(-0.5, 148.5)\n\n    overlay = ax.get_coords_overlay('fk5')\n    overlay.grid(color='purple', ls='dotted')\n\n    canvas.draw()",
        "min_run_count": 2,
        "name": "visualization.wcsaxes.time_basic_plot_with_grid_and_overlay",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "af06e413366d2baecf8ed41973c1c393c8ac99f49857791375ebbbcd51e9785e",
        "warmup_time": -1
    },
    "visualization.wcsaxes.time_contour_with_transform": {
        "code": "def time_contour_with_transform():\n\n    fig = Figure()\n    canvas = FigureCanvas(fig)\n\n    ax = WCSAxes(fig, [0.15, 0.15, 0.7, 0.7], wcs=MSX_WCS)\n    fig.add_axes(ax)\n\n    ax.contour(DATA, transform=ax.get_transform(TWOMASS_WCS))\n\n    # The limits are to make sure the contours are in the middle of the result\n    ax.set_xlim(32.5, 150.5)\n    ax.set_ylim(-64.5, 64.5)\n\n    canvas.draw()",
        "min_run_count": 2,
        "name": "visualization.wcsaxes.time_contour_with_transform",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "16f5ca0692fab47aedd082450d02be38966127df2778d31fea039005c67c7a92",
        "warmup_time": -1
    },
    "visualization.wcsaxes.time_contourf_with_transform": {
        "code": "def time_contourf_with_transform():\n\n    fig = Figure()\n    canvas = FigureCanvas(fig)\n\n    ax = WCSAxes(fig, [0.15, 0.15, 0.7, 0.7], wcs=MSX_WCS)\n    fig.add_axes(ax)\n\n    ax.contourf(DATA, transform=ax.get_transform(TWOMASS_WCS))\n\n    # The limits are to make sure the contours are in the middle of the result\n    ax.set_xlim(32.5, 150.5)\n    ax.set_ylim(-64.5, 64.5)\n\n    canvas.draw()",
        "min_run_count": 2,
        "name": "visualization.wcsaxes.time_contourf_with_transform",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "94c5584b7804b5ae0e8b922d32d60340b5ccc3b05ff59f0dbd4436f8ebeeff6c",
        "warmup_time": -1
    }
}